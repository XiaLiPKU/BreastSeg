# **Quantifying the "Vanishing Lesion": A Physics-Based Analysis of VAE Spatial Compression in Volumetric Segmentation**

## **1\. Introduction**

### **1.1 The Dimensionality Crisis in Medical Physics**

The trajectory of modern medical imaging is defined by an aggressive pursuit of higher spatial and temporal resolution. From isotropic sub-millimeter Computed Tomography (CT) to high-field multi-parametric Magnetic Resonance Imaging (MRI), the volume of data generated per patient encounter has grown exponentially. In the context of *Physics in Medicine & Biology*, this "data deluge" presents a fundamental paradox. While higher resolution acquisition offers the theoretical potential to detect pathologies at their nascent stages—such as micro-calcifications in breast tissue or sub-centimeter pulmonary nodules—it simultaneously renders the computational analysis of this data increasingly intractable.1

The storage, transmission, and processing of 4D volumetric data (3D space \+ time/sequence) impose severe constraints on clinical workflows and research pipelines. Training state-of-the-art deep learning models, particularly 3D Convolutional Neural Networks (CNNs) and Transformers, on raw high-resolution tensors is often prohibited by GPU memory limitations. A single ![][image1] voxel volume with float32 precision occupies significant VRAM, and efficient batch training requires dimensionality reduction. Consequently, the field has coalesced around the use of Generative AI frameworks, specifically **Latent Diffusion Models (LDMs)** and **Variational Autoencoders (VAEs)**, as the standard solution for handling high-dimensional medical data.

These models fundamentally rely on **spatial compression**: encoding high-dimensional voxel data (![][image2]) into a compact, low-dimensional latent representation (![][image3]).2 By mapping the data to a latent manifold, researchers can train complex generative and segmentation models on a compressed representation that is computationally manageable. For instance, the NVIDIA MAISI framework, a leading foundation model for medical image synthesis, utilizes a VAE to compress 3D volumes by a spatial factor of 4, reducing the total voxel count by a factor of 64 before applying generative diffusion processes.4 This reduction is not merely a convenience; it is a prerequisite for the feasibility of foundation models in medical imaging.

### **1.2 The "Vanishing Structure" Problem**

However, this reliance on VAE-based compression introduces a critical, often under-quantified risk: the "Vanishing Structure" problem. While VAEs are remarkably effective at encoding and reconstructing global anatomical structures (e.g., the liver, the skull, the ventricles), they function as non-linear low-pass filters that disproportionately degrade high-frequency spatial details.5

In clinical physics, the "signal" of interest is frequently the "outlier"—the small tumor, the vascular stenosis, the micro-aneurysm—rather than the background anatomy. These pathological features often occupy fewer voxels than the downsampling factor of the VAE bottleneck. A 4x downsampling operation on a 1mm isotropic scan means a single latent voxel represents a ![][image4] volume. Features smaller than this "latent pixel" risk being aliased, smoothed, or entirely omitted during the encoding process.6

Furthermore, the probabilistic regularization inherent to VAEs, enforced by the Kullback-Leibler (KL) divergence penalty, encourages the latent space to follow a smooth, Gaussian distribution. This regularization penalizes the encoding of high-information-density outliers (i.e., lesions) in favor of preserving the dominant low-frequency statistics of the background anatomy.7 The result is a reconstructed volume that is "perceptually" high-quality but medically compromised, where small lesions may be morphologically distorted or "healed" (removed) entirely.

### **1.3 Scope and Objectives**

This report provides an exhaustive technical analysis of VAE spatial compression effects on the segmentation of small anatomical structures. Targeting the *Physics in Medicine & Biology* audience, we synthesize theoretical principles from signal processing and information theory with empirical benchmarks from recent deep learning literature.

The report is structured to address three core areas of investigation:

1. **Mechanism of Resolution Loss:** We analyze the physics of the VAE information bottleneck, treating the encoder as a spectral filter and quantifying the loss of spatial resolution through the lens of Nyquist-Shannon sampling theory and manifold topology.  
2. **Small Structure Preservation Strategies:** We evaluate architectural and loss-function based mitigations, including Weighted Cross-Entropy (WCE), Region-Specific Contrastive Loss (as seen in MAISI-v2), and hierarchical latent structures.  
3. **Quantitative Benchmarking:** We synthesize evidence from recent literature (MAISI, MedSegLatDiff, ZFP studies) to establish robust relationships between compression ratios (CR) and downstream segmentation metrics (Dice, IoU, Hausdorff Distance).

## ---

**2\. Theoretical Framework: The Physics of the Information Bottleneck**

### **2.1 The Variational Inference Mechanism**

To understand why small structures vanish, one must first deconstruct the mathematical machinery of the Variational Autoencoder. A VAE is not simply a data compressor; it is a probabilistic graphical model that attempts to approximate the intractable posterior distribution of the data.

The model consists of two coupled networks:

1. **The Probabilistic Encoder (![][image5]):** Maps the input volumetric data ![][image2] to a distribution in the latent space ![][image3]. In medical imaging, this is typically a 3D CNN that progressively reduces spatial dimensions while increasing channel depth.  
2. **The Probabilistic Decoder (![][image6]):** Samples from the latent distribution ![][image3] and attempts to reconstruct the original volume ![][image2].

The training objective is to maximize the **Evidence Lower Bound (ELBO)**:

$$ \\mathcal{L}*{\\text{ELBO}} \= \\mathbb{E}*{q\_\\phi(z|x)}\[\\log p\_\\theta(x|z)\] \- \\beta D\_{\\text{KL}}(q\_\\phi(z|x) |

| p(z)) $$

This equation reveals the fundamental tension in VAE design, which can be interpreted through a physics lens as a conflict between **fidelity** and **entropy**.

#### **2.1.1 The Reconstruction Term (Fidelity)**

The first term, ![][image7], represents the reconstruction likelihood. It drives the model to encode enough information to perfectly reproduce the input. If this were the sole objective, the model would behave like a standard deterministic autoencoder, potentially learning an identity mapping if capacity allowed. However, even in deterministic autoencoders, the discrete spatial downsampling acts as a bottleneck.

#### **2.1.2 The Regularization Term (Entropy/Compression)**

The second term, $\\beta D\_{\\text{KL}}(q\_\\phi(z|x) |

| p(z))$, is the Kullback-Leibler divergence between the learned posterior and a fixed prior ![][image8] (typically a standard normal distribution ![][image9]). This term acts as a **regularizer**. It penalizes the model for encoding information in complex, highly peaked distributions. Ideally, the latent space should be smooth, continuous, and normally distributed.

In the context of medical anomalies, this term is destructive. A small, distinct anatomical feature (e.g., a 3mm lung nodule) represents a high-frequency, high-information "outlier" in the data distribution. To encode this outlier accurately, the encoder would need to produce a latent distribution that diverges significantly from the standard normal prior (i.e., a "spike" in the latent manifold). The KL-divergence term explicitly penalizes such spikes. Consequently, under strong regularization (high ![][image10]), the model is incentivized to "smooth out" the outlier, merging it with the surrounding background distribution to satisfy the prior. This is the **thermodynamic cost** of VAE compression: the erasure of negentropy (structure) to maximize entropy (smoothness).8

### **2.2 Spectral Bias and the Low-Pass Filter Effect**

From a signal processing perspective, the VAE bottleneck acts as a **non-linear low-pass filter**. Neural networks inherently exhibit "spectral bias," converging on low-frequency components of the target function before learning high-frequency details.

#### **2.2.1 The Nyquist Limit of the Latent Space**

Most 3D VAE architectures in medical imaging, such as those used in MAISI or Stable Diffusion adaptations, employ a strided convolution architecture that results in a fixed downsampling factor ![][image11].

* **MAISI VAE:** Utilizes a ![][image12] spatial compression. An input volume of ![][image13] voxels is compressed to a latent grid of ![][image14].4  
* **The Latent Voxel:** A single voxel in the latent space represents a ![][image12] block of pixels in the original space. If the input resolution is 1mm isotropic, the "latent resolution" is effectively 4mm.

According to the Nyquist-Shannon sampling theorem, a digital system can only reconstruct spatial frequencies less than half the sampling rate. If the "sampling rate" of the latent space is 1 sample per 4mm, then any anatomical feature with a spatial frequency higher than 0.125 cycles/mm (i.e., features smaller than 8mm) cannot be uniquely represented without aliasing, unless the encoder learns a highly robust super-resolution code in the channel dimension.10 In practice, this manifests as **aliasing artifacts**, where small structures are either blurred into the background (if filtered) or appear as distorted "ringing" patterns (if aliased).11

### **2.3 The Manifold Hypothesis and Pathological Perturbations**

VAEs rely on the **Manifold Hypothesis**: the assumption that high-dimensional data (like medical images) lie on a lower-dimensional manifold embedded within the pixel space. The VAE attempts to learn the coordinate system of this manifold.

While this holds for gross anatomy (all healthy livers share a common topological structure), pathologies are often **perturbations** *off* this healthy manifold. A tumor is not a "standard variation" of normal tissue; it is a topological anomaly.

* **Projective Healing:** A VAE trained primarily on healthy data (or where pathology is a minority class) learns the manifold of healthy anatomy. When presented with a pathological image, the encoder projects the input onto the nearest point on the *learned* manifold. Since the learned manifold may not contain the "tumor" dimension, the projection effectively "heals" the image, reconstructing it as healthy tissue.  
* **Implication for Segmentation:** If the segmentation model operates on this latent representation (as in Latent Diffusion Segmentation), it is effectively blinded to the pathology. The segmentation mask will reflect the "healed" anatomy, leading to a False Negative.12

## ---

**3\. Architectural Mechanisms of Resolution Loss**

### **3.1 Spatial Downsampling vs. Channel Expansion**

To compensate for the loss of spatial resolution, VAE architectures typically expand the channel dimension. The theory is that spatial information can be "folded" into the channel dimension (e.g., PixelShuffle or Space-to-Depth operations).

* **MAISI VAE:** Compresses 1 channel (grayscale CT) ![][image15] 4 channels (Latent). The total data reduction is ![][image16].  
* **Information Bottleneck:** Despite the channel expansion, the receptive field of the convolution operations and the aggregation of pooling layers mean that local spatial relationships are inevitably diluted. A channel vector at position ![][image17] in the latent space must encode the intensity, texture, and edge information for 64 original voxels. If 63 of those voxels are "lung parenchyma" and 1 is "nodule," the "nodule" signal is easily drowned out by the "parenchyma" signal during the aggregation functions (Average Pooling or Strided Convolution).6

### **3.2 Discrete vs. Continuous Latent Spaces**

While standard VAEs use continuous Gaussian latent spaces, **Vector Quantized VAEs (VQ-VAEs)** use a discrete latent space.

* **VQ-VAE Mechanism:** The latent vectors are snapped to the nearest entry in a learned codebook.  
* **Relevance to Small Structures:** VQ-VAEs avoid the KL-divergence smoothing problem because they do not enforce a Gaussian prior. However, they suffer from **quantization error**. If the codebook does not contain a "code" that represents "small hyperdense nodule edge," the model will substitute it with the nearest available code (e.g., "healthy vessel"), leading to semantic substitution errors.14

### **3.3 The "Posterior Collapse" in Medical Imaging**

In medical datasets, the variance between samples is often subtle (e.g., two brain MRI scans differ less than two natural images of a dog and a cat). This makes medical VAEs particularly prone to **Posterior Collapse**, where the decoder learns to ignore the latent code ![][image3] and simply model the average dataset statistics (the "mean patient").

* **Impact:** When posterior collapse occurs, the reconstruction lacks specific patient details. Small, unique identifiers like lesion shape or vessel topology are replaced by generic, average features. This is catastrophic for precision medicine tasks like surgical planning, where the *specific* topology of the patient is the only thing that matters.15

## ---

**4\. Small Structure Preservation in Latent Space Models: Mitigation Strategies**

The physics of VAE compression suggest that small structure loss is inevitable in vanilla architectures. However, recent research has introduced sophisticated mitigation strategies focusing on loss function engineering and architectural modifications.

### **4.1 Loss Function Engineering**

The most effective interventions found in the literature involve modifying the loss landscape to penalize the loss of small structures explicitly.

#### **4.1.1 Weighted Cross-Entropy (WCE)**

The **MedSegLatDiff** framework (Latent Diffusion for Medical Segmentation) identifies the standard Mean Squared Error (MSE) reconstruction loss as a primary culprit. In a volume where a nodule occupies \<0.1% of voxels, an MSE-optimized model achieves \>99.9% accuracy by predicting "background" everywhere.

* **The Solution:** Replace MSE in the mask reconstruction path with **Weighted Cross-Entropy (WCE)**.16  
* **Mechanism:** WCE assigns a weight vector ![][image18] to the loss, where ![][image19]. This creates a massive gradient penalty for missing a lesion voxel, forcing the encoder to allocate "bandwidth" in the latent space to these features despite their small spatial footprint.  
* **Empirical Impact:** As detailed in the Benchmarks section, this single change can improve Dice scores for tiny nodules by over 6 points.18

#### **4.1.2 Region-Specific Contrastive Loss (MAISI-v2)**

The **MAISI-v2** framework introduces a novel **Region-Specific Contrastive Loss** to enhance sensitivity to small tumors.4

* **The Problem:** Global contrastive loss (e.g., SimCLR or CLIP-style) aligns the *entire* volume's representation. Since the volume is 99% healthy tissue, the contrastive objective is satisfied by aligning healthy anatomy, ignoring the tumor.  
* **The Solution:** The model identifies Regions of Interest (ROI) containing pathology. It computes a contrastive loss *specifically* on the feature vectors corresponding to these ROIs.  
  * *Positive Pairs:* Latent patch of Tumor X in View A ![][image20] Latent patch of Tumor X in View B.  
  * *Negative Pairs:* Latent patch of Tumor X ![][image20] Latent patch of Healthy Tissue (even if visually similar).  
* **Implementation Detail:** To manage GPU memory for high-res 3D volumes, MAISI-v2 applies this loss adaptively. For large inputs, it is computed on the *ControlNet encoder features* (coarser but memory-efficient). For smaller inputs, it is computed on the *frozen diffusion model outputs* (higher fidelity).4

#### **4.1.3 Perceptual Losses (LPIPS)**

Moving beyond pixel-wise losses, **Perceptual Losses** (like LPIPS) use the feature maps of a pre-trained network (e.g., VGG or a medical ResNet) to measure similarity.

* **Mechanism:** Instead of asking "do the pixels match?", LPIPS asks "do the features match?".  
* **Benefit:** This helps preserve "texture" and "sharpness." A small nodule might be slightly displaced (bad MSE) but texturally preserved (good LPIPS).  
* **Risk:** Perceptual losses can induce "hallucinations." The model might reconstruct a sharp-looking vessel that doesn't actually exist, simply to satisfy the texture statistic. For segmentation, this is a dangerous trade-off.2

### **4.2 Architectural Interventions**

#### **4.2.1 Hierarchical and Multi-Scale VAEs**

To mitigate the information bottleneck, **Hierarchical VAEs (H-VAEs)** and **Multi-Scale VAEs** effectively widen the bottleneck by splitting the latent variable into groups.19

* **Mechanism:** The latent space is factorized into ![][image21].  
  * ![][image22] (deepest layer): Encodes global shape (low frequency).  
  * ![][image23] (shallowest layer): Encodes fine details and texture (high frequency).  
* **Medical Application:** In **MeshVAE** for organ modeling, this hierarchical structure allows the model to separate global organ deformation from local surface irregularities (e.g., tumor protrusions), preventing the global shape prior from smoothing out the local anomaly.20  
* **MSVQ-VAE:** A Multi-Scale VQ-VAE designed for endoscopy demonstrated that retaining multi-resolution feature maps is critical for detecting small abnormalities in the GI tract, which would be lost in a single-scale latent space.21

#### **4.2.2 The Skip Connection Dilemma**

In deterministic U-Nets, skip connections shuttle high-frequency features from encoder to decoder, bypassing the bottleneck. In VAEs, introducing deterministic skip connections is controversial.

* **Pros:** Ideally preserves resolution (like a U-Net).  
* **Cons:** It breaks the generative strictness. If the decoder relies on the skip connection, the latent space ![][image3] becomes less informative (information bypass). You can no longer sample new images just from ![][image3].  
* **Hybrid Models:** Architectures like **GAEI-UNet** use "elastic interaction-based" losses or auxiliary paths to allow gradients to flow for segmentation while maintaining a VAE branch for regularization, attempting to get the best of both worlds.22

## ---

**5\. Quantitative Benchmarks and Comparative Analysis**

To move beyond theoretical abstraction, we must examine the empirical evidence. The literature provides several key benchmarks that quantify the relationship between compression and small structure segmentation.

### **5.1 Deep Dive: MedSegLatDiff and the Weighted Cross-Entropy Effect**

The **MedSegLatDiff** study provides one of the most direct evaluations of VAE-based segmentation for small objects, specifically testing on the **LIDC-IDRI** (lung nodule) dataset.

**Table 1: Impact of VAE Loss Function on Segmentation Metrics (LIDC-IDRI)**

| Model Configuration | Target Structure | Metric | Score | Analysis |
| :---- | :---- | :---- | :---- | :---- |
| **Baseline (MedSegDiff)** | Lung Nodules | Dice | 82.8 | Standard MSE-based VAE struggles with tiny masks. |
| **MedSegLatDiff (MSE)** | Lung Nodules | Dice | \~88.0 | Latent space improves global coherence but misses tiny nodules. |
| **MedSegLatDiff (WCE)** | Lung Nodules | Dice | **94.4** | **\+6.4** improvement. WCE forces latent preservation of small features. |
| **MedSegLatDiff (WCE)** | Lung Nodules | IoU | **89.4** | **\+6.3** improvement over baseline. |

Source: Synthesized from 18

**Insight:** The massive jump in performance with WCE proves that the **latent space capacity** is not the primary limiting factor; rather, the **optimization objective** (loss function) is. The VAE *can* encode small nodules, but it *won't* unless heavily penalized for ignoring them.

### **5.2 Deep Dive: Efficiency vs. Efficacy (The ZFP Benchmark)**

A pivotal study titled *"Efficiency vs. Efficacy"* 24 benchmarks 3D cerebrovascular segmentation using **ZFP** (a classical, non-learned compression algorithm). While ZFP is not a VAE, this study acts as a critical control: it shows how segmentation models behave under *mathematically bounded* compression versus *probabilistic* (VAE) compression.

**Table 2: Compression Ratio vs. Segmentation Fidelity (ZFP Benchmark)**

| Mode | Compression Param | Compression Ratio (CR) | Mean Dice (DSC) | Interpretation |
| :---- | :---- | :---- | :---- | :---- |
| **Baseline** | Uncompressed | 1:1 | 0.8774 | Reference Standard |
| **Fixed-Rate** | 16 bits/voxel | \~1:1 | 0.8774 | Lossless equivalent |
| **Fixed-Rate** | 4 bits/voxel | \~4:1 | 0.8771 | High fidelity maintained |
| **Fixed-Rate** | 2 bits/voxel | \~8:1 | 0.8773 | Robust to 8x compression |
| **Error Tol** | Tol \= 500 | **22.89:1** | **0.8766** | **Critical Benchmark** |
| **Error Tol** | Tol \= 1500 | 49.12:1 | 0.8606 | Breakdown threshold |

Source: Synthesized from 1

**Comparison with VAEs:**

* **Robustness:** The segmentation model (VesselMamba++) remained robust (Dice \> 0.87) even at **23x compression**.  
* **Mechanism:** ZFP induces **high-frequency noise** artifacts but tends to preserve **topology** (connectivity of vessels).  
* **Contrast:** VAEs typically achieve lower CRs (e.g., 16x) but induce **morphological smoothing**. The study implies that for segmentation, *statistical noise* (ZFP) is less damaging than *semantic smoothing* (VAE). A VAE might produce a "cleaner" looking image that yields a lower Dice score because the vessel boundaries have been shifted or disconnected by the decoder's smooth prior.

### **5.3 Deep Dive: MAISI VAE Performance**

The **MAISI VAE** (used in MAISI-v1/v2) represents the state-of-the-art in Foundation Model compression.

**Table 3: MAISI VAE Reconstruction Metrics**

| Dataset | Target Anatomy | LPIPS (↓) | SSIM (↑) | PSNR (↑) |
| :---- | :---- | :---- | :---- | :---- |
| **MSD Task07** | Pancreas Tumor | 0.038 | 0.978 | 37.266 |
| **MSD Task08** | Hepatic Vessels | 0.046 | 0.970 | 36.559 |
| **BraTS18** | Brain Tumor | 0.026 | 0.977 | 39.003 |

Source: 2

**Analysis:**

* **High SSIM:** Scores \> 0.97 suggest excellent fidelity.  
* **The LPIPS Factor:** The low LPIPS scores (0.026-0.046) are crucial. Unlike SSIM, LPIPS correlates with perceptual sharpness. This suggests MAISI's VAE preserves texture well.  
* **The Segmentation Gap:** Despite these high reconstruction scores, MAISI-v2 still required the introduction of **Region-Specific Contrastive Loss** to accurately handle small tumors.4 This confirms that global metrics like SSIM are insufficient proxies for small-structure segmentation performance. A model can have 0.978 SSIM and still miss the core of a small tumor if the contrast is washed out.

### **5.4 The "Dice Paradox" for Small Objects**

This analysis highlights a flaw in using the Dice Similarity Coefficient (DSC) as the sole metric for this research.

* **Surface-to-Volume Ratio:** For a small lesion (e.g., 100 voxels), the surface voxels comprise a significant fraction of the total volume. A VAE-induced spatial shift of 1 voxel at the boundary (due to aliasing) can reduce the intersection by 50%, causing the Dice score to plummet from 0.9 to 0.4.  
* **Recommendation:** Future research in *Physics in Medicine & Biology* should prioritize **Surface Distance Metrics** (Hausdorff Distance, ASSD) and **Detection Sensitivity** (FROC) over Dice for evaluating VAE compression effects on small structures.26

## ---

**6\. The Diffusion Paradigm: Latent vs. Pixel Space**

The choice between Latent Diffusion (LDM) and Pixel Diffusion (PDM) is the defining architectural decision in modern medical generative AI. This choice is fundamentally a trade-off between **efficiency** and **resolution**.

### **6.1 Computational Economics**

* **Latent Diffusion (MAISI, Stable Diffusion):**  
  * **Efficiency:** MAISI-v2 reports a **33x acceleration** in inference speed compared to pixel-based equivalents.27  
  * **Memory:** By compressing the volume ![][image24] (spatially), LDMs allow the processing of large ![][image13] volumes on standard clinical GPUs.  
  * **Scaling:** LDMs scale better with dataset size, as the VAE decouples the "compression" learning from the "generative" learning.

### **6.2 The Upper Bound Theorem**

* **Performance Cap:** The performance of an LDM is strictly **upper-bounded** by the performance of its VAE. If the VAE fails to encode a 2mm tumor, the diffusion model—no matter how powerful—cannot generate or segment it.  
* **Pixel Diffusion Advantage:** Pixel diffusion models operate on the raw data. They have no bottleneck. Consequently, they consistently outperform LDMs in **PSNR** and **fine detail recovery**, particularly in sparse-view reconstruction tasks where the input is noisy.28  
* **Sparse Data Reconstruction:** In scenarios like Low-Dose CT or Accelerated MRI, pixel diffusion models show superior capability in recovering small structures because they are not constrained by the VAE's "smoothness" prior, which might interpret the sparse signal as noise and filter it out.29

### **6.3 Hybrid Architectures: The Best of Both Worlds?**

Recent literature suggests a convergence toward **Cascaded Architectures**:

1. **Stage 1:** A Latent Diffusion Model generates a global anatomical volume (high coherence, low resolution/texture).  
2. **Stage 2:** A Pixel-Space Super-Resolution model (or "Upsampler") refines the output, adding high-frequency details conditioned on the LDM output.30 This approach mimics the "Coarse-to-Fine" strategy of biological vision and appears to be the most promising path for resolving the resolution-efficiency conflict.

## ---

**7\. Clinical & Physical Implications**

The implications of VAE compression extend beyond computer science into clinical physics and patient safety.

### **7.1 Dosimetry and Radiotherapy Planning**

In radiation oncology, the **Gross Tumor Volume (GTV)** must be delineated with extreme precision.

* **Edge Preservation:** A VAE-induced blurring of the tumor boundary by even 1-2 voxels can have significant dosimetric consequences.  
  * *Under-segmentation:* The PTV (Planning Target Volume) margin might miss microscopic spread, leading to recurrence.  
  * *Over-segmentation:* OARs (Organs at Risk) might receive toxic doses.  
* **Small Targets:** For stereotactic radiosurgery (SRS) of brain metastases (often \<1cm), VAE aliasing could render the segmentation useless for dose calculation. The "Efficiency vs. Efficacy" study suggests that for these tasks, topology-preserving compression (like ZFP) or pixel-space refinement is non-negotiable.24

### **7.2 Diagnostic Confidence**

For AI-assisted diagnosis (CAD), the "Vanishing Structure" problem poses a **False Negative** risk.

* **Posterior Collapse:** If a VAE reconstructs a small lesion as healthy tissue due to posterior collapse, the radiologist using the tool (e.g., for anomaly detection) might be misled.  
* **Uncertainty Quantification:** Generative models can output "uncertainty maps." However, if the VAE is confident in its "healed" reconstruction (because it satisfies the prior perfectly), the uncertainty map will be falsely low. This "confident failure" is a critical safety mode that must be evaluated.18

## ---

**8\. Conclusion**

The integration of Variational Autoencoders into medical imaging pipelines represents a necessary compromise between computational feasibility and spatial fidelity. This comprehensive analysis leads to the following conclusions for the *Physics in Medicine & Biology* community:

1. **Compression is Non-Negligible:** VAE spatial compression is a semantic low-pass filter. For structures smaller than the latent receptive field (typically \< 3-4 voxels), significant information loss occurs. This is a physical limitation of the Nyquist sampling rate in the latent space.  
2. **Loss Function Dominance:** The standard ELBO objective is insufficient for small structure preservation. The adoption of **Weighted Cross-Entropy (WCE)** and **Region-Specific Contrastive Losses** (as seen in MAISI-v2 and MedSegLatDiff) is mandatory. Empirical data shows WCE can improve small-nodule Dice scores by over 6 points, proving that the latent space *capacity* exists but is under-utilized by standard losses.  
3. **Efficiency Wins (for now):** Despite the resolution drawbacks, Latent Diffusion Models (using VAEs) remain the pragmatic standard due to massive efficiency gains (33x speedup). The community is likely to address the resolution gap not by abandoning VAEs, but by enhancing them with hierarchical latents and cascaded pixel-refinement stages.  
4. **Robustness of Classical Methods:** The surprising robustness of ZFP compression suggests that learned compression (VAE) has not yet fully optimized the "topology-preservation" objective. Future VAEs could benefit from hybridizing learned priors with classical frequency-domain constraints to prevent the topological erasure of small vessels and lesions.

For the medical physicist, the takeaway is clear: **Do not trust the latent representation blindly.** Validation of VAE-based models must specifically stress-test the preservation of the smallest, rarest features in the dataset, using metrics that penalize boundary loss and topological changes more severely than pixel-wise error.

---

*End of Report.*

#### **Works cited**

1. Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2510.03769v1](https://arxiv.org/html/2510.03769v1)  
2. MAISI: Medical AI for Synthetic Imaging \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2409.11169v3](https://arxiv.org/html/2409.11169v3)  
3. High-Resolution Image Synthesis with Latent Diffusion Models \- Computer Vision & Learning Group, accessed February 10, 2026, [https://ommer-lab.com/research/latent-diffusion-models/](https://ommer-lab.com/research/latent-diffusion-models/)  
4. MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2508.05772v1](https://arxiv.org/html/2508.05772v1)  
5. VAE. The Latent Bottleneck: Why Image Generation Processes Lose Fine Details \- Medium, accessed February 10, 2026, [https://medium.com/@efrat\_taig/vae-the-latent-bottleneck-why-image-generation-processes-lose-fine-details-a056dcd6015e](https://medium.com/@efrat_taig/vae-the-latent-bottleneck-why-image-generation-processes-lose-fine-details-a056dcd6015e)  
6. Unconditional Latent Diffusion Models Memorize Patient Imaging Data: Implications for Openly Sharing Synthetic Data \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2402.01054v3](https://arxiv.org/html/2402.01054v3)  
7. Unsupervised Learning of Disentangled Representation via Auto-Encoding: A Survey \- NIH, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9960632/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9960632/)  
8. Disentangle, align and fuse for multimodal and semi-supervised image segmentation \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8011298/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8011298/)  
9. Information Flows of Diverse Autoencoders \- MDPI, accessed February 10, 2026, [https://www.mdpi.com/1099-4300/23/7/862](https://www.mdpi.com/1099-4300/23/7/862)  
10. Superresolution parallel magnetic resonance imaging: Application to functional and spectroscopic imaging \- PMC \- PubMed Central, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC2782710/](https://pmc.ncbi.nlm.nih.gov/articles/PMC2782710/)  
11. Reduced aliasing artifacts using variable-density k-space sampling trajectories \- PubMed, accessed February 10, 2026, [https://pubmed.ncbi.nlm.nih.gov/10725889/](https://pubmed.ncbi.nlm.nih.gov/10725889/)  
12. Tri-VAE: Triplet Variational Autoencoder for Unsupervised Anomaly Detection in Brain Tumor MRI \- CVF Open Access, accessed February 10, 2026, [https://openaccess.thecvf.com/content/CVPR2024W/VAND/papers/Wijanarko\_Tri-VAE\_Triplet\_Variational\_Autoencoder\_for\_Unsupervised\_Anomaly\_Detection\_in\_Brain\_CVPRW\_2024\_paper.pdf](https://openaccess.thecvf.com/content/CVPR2024W/VAND/papers/Wijanarko_Tri-VAE_Triplet_Variational_Autoencoder_for_Unsupervised_Anomaly_Detection_in_Brain_CVPRW_2024_paper.pdf)  
13. Brain Tumor Segmentation Using Generative Adversarial Networks \- IEEE Xplore, accessed February 10, 2026, [https://ieeexplore.ieee.org/iel8/6287639/10380310/10649559.pdf](https://ieeexplore.ieee.org/iel8/6287639/10380310/10649559.pdf)  
14. High-quality Tumor Synthesis for Breast Tumor Segmentation by 3D Diffusion Model \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2509.03267v1](https://arxiv.org/html/2509.03267v1)  
15. Use of Variational Autoencoders with Unsupervised Learning to ..., accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8328105/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8328105/)  
16. Toan Nguyen Hai's research works \- ResearchGate, accessed February 10, 2026, [https://www.researchgate.net/scientific-contributions/Toan-Nguyen-Hai-2332683938](https://www.researchgate.net/scientific-contributions/Toan-Nguyen-Hai-2332683938)  
17. (PDF) Diffusion Model in Latent Space for Medical Image ..., accessed February 10, 2026, [https://www.researchgate.net/publication/398226489\_Diffusion\_Model\_in\_Latent\_Space\_for\_Medical\_Image\_Segmentation\_Task](https://www.researchgate.net/publication/398226489_Diffusion_Model_in_Latent_Space_for_Medical_Image_Segmentation_Task)  
18. Diffusion Model in Latent Space for Medical Image Segmentation Task \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2512.01292v2](https://arxiv.org/html/2512.01292v2)  
19. Unified Brain MR-Ultrasound Synthesis using Multi-Modal Hierarchical Representations \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC7615858/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7615858/)  
20. Construction of an Organ Shape Atlas Using a Hierarchical Mesh Variational Autoencoder, accessed February 10, 2026, [https://arxiv.org/html/2506.15557v1](https://arxiv.org/html/2506.15557v1)  
21. Multiscale Vector-Quantized Variational Autoencoder for Endoscopic Image Synthesis \- arXiv, accessed February 10, 2026, [https://www.arxiv.org/pdf/2511.19578](https://www.arxiv.org/pdf/2511.19578)  
22. arXiv daily: Image and Video Processing (eess.IV) \- Science Cast, accessed February 10, 2026, [https://sciencecast.org/podcasts/arxiv\_daily/image-and-video-processing](https://sciencecast.org/podcasts/arxiv_daily/image-and-video-processing)  
23. Diffusion Model in Latent Space for Medical Image Segmentation Task \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2512.01292v1](https://arxiv.org/html/2512.01292v1)  
24. (PDF) Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice ..., accessed February 10, 2026, [https://www.researchgate.net/publication/396249839\_Efficiency\_vs\_Efficacy\_Assessing\_the\_Compression\_Ratio-Dice\_Score\_Relationship\_through\_a\_Simple\_Benchmarking\_Framework\_for\_Cerebrovascular\_3D\_Segmentation](https://www.researchgate.net/publication/396249839_Efficiency_vs_Efficacy_Assessing_the_Compression_Ratio-Dice_Score_Relationship_through_a_Simple_Benchmarking_Framework_for_Cerebrovascular_3D_Segmentation)  
25. Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation \- arXiv, accessed February 10, 2026, [https://arxiv.org/html/2510.03769v3](https://arxiv.org/html/2510.03769v3)  
26. A systematic comparison of generative models for medical images \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9206635/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9206635/)  
27. tutorials/generation/maisi/README.md at main \- GitHub, accessed February 10, 2026, [https://github.com/Project-MONAI/tutorials/blob/main/generation/maisi/README.md](https://github.com/Project-MONAI/tutorials/blob/main/generation/maisi/README.md)  
28. DM4CT: BENCHMARKING DIFFUSION MODELS FOR COMPUTED TOMOGRAPHY RECONSTRUCTION \- OpenReview, accessed February 10, 2026, [https://openreview.net/pdf/6c6275f2f22d44d9ad3dc21ea1c8d7155eaed09b.pdf](https://openreview.net/pdf/6c6275f2f22d44d9ad3dc21ea1c8d7155eaed09b.pdf)  
29. A state-of-the-art review of diffusion model applications for microscopic image and micro-alike image analysis \- Frontiers, accessed February 10, 2026, [https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1551894/full](https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1551894/full)  
30. MRI super-resolution reconstruction for MRI-guided adaptive radiotherapy using cascaded deep learning: In the presence of limited training data and unknown translation model, accessed February 10, 2026, [https://profiles.wustl.edu/en/publications/mri-super-resolution-reconstruction-for-mri-guided-adaptive-radio/](https://profiles.wustl.edu/en/publications/mri-super-resolution-reconstruction-for-mri-guided-adaptive-radio/)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIYAAAAXCAYAAADOQzd3AAAEd0lEQVR4Xu2ZW8hVRRTHl2UJ+SalD6GQ0VXzilGiYhQUYkSI+CAiJJGSlEYakeJDhkpWJNmFKFELUikUfdDwIcLAF9GHxDRRzO7kpaSim7X+rj3nm/0/M7PnfObBh/nBn3POf61v75l91pnbJ1IoFAqFQqFw6Vio2qS6vfp8q+o91YJWRp2+qj/Z9Jij+lX1r2onxbrFWdXzqsFi7b1Lta+WUWeK2DOI8b5Yf35XLadYt/hKNVXVX3Wdaq6kv4eNqtvYrLhG9blYn46qhtbDBjqKBF/7axnGF1LPCYGHP7t6f6X05PZrZXQH7g+EH4DPYtW5KgZtrodbIHZt9X5k9fmfnnDX4P5AV9cyRPaozlcxyP3YfW5Q/eB93i2Wu9rzLrBMtUa1XrVE7AtN8YvYhZgrVH+phngeqhu5qcq+FOCez4r16TGKhYgVxjOqA2J9cywSy3/Z87qBu+crqjsoxoyReGHA5x+JK6QaKIZ72EwQK4wHJHyDkBfiaTaIQWwk+JuNBmKFsVcs9hr5uX16mA1iOhsJcu7naCoMvtaWypvnm8/J/1MY4B2xocon1JAQE8TmvRA3q75hMwFGrk6IFQbm4g+lPmJgWsztE/52PpsVL6pWsZkg536OVGE8JO0jxidi+Q/6JobcF6rAuur1LT+BSBUGgweL3JMciHCv6gh5t6i+I6+JP1RrVT+rPhBrw/haRp1YYYTA80L+4xyIsF1s+vF5STqfinBPLKo/Ux0W61uMVGGECBb6U6pd5CEJq/oQnRTGb5Kf67hP9WX1HkXxvRfLBW283/t8p1g7BnieD2IYTnNA7mk2G9ghttgFKIpXvVgu/BzRBvYcrjCGcSAApjPkzuBAiGAFVeQWxpNieU2L2RCuOH7kwEWAtqDtIRDDsN8E2vQTm5mgOD5Vvc6BXoLtKto9kQPSUxhNi9Q+YnmPcgAgyGA7FvvycwpjrNi2qbegYxgpjnMgk6vYkHSxw/+ITQJnGQfZ7IB1Ylv+pRzoJZPF2v0G+cAVxggOEMiJri8RPBXwYg+xqTCw58dBkE/uGgOgU25NgSkABzCdMEusfTyvp/oEfyubHk+oPiYvdq0QKApsMwEOD7FO6QR3NuGDwy54oQM3VxijOOCBaf4m7/ONYoeTLTp9iKnCwLRxhk2J5zOjVd+Sh+LgBWmKR8Tudz358GLXQWwbmxWTxE4RmdzR413pKQoHioOfeQq0j3dlKyvfPzdyuMLA8wxxTDWQPCzWcaLaApXjG5PFLoqFX4jUgtIVFCtnWhmuOsFmxTixYTgXbh/md/YcOD1EDKt9BsXFfXFa4eXFeFNsxxdig7RvG2NMk/YRDW04RJ4DR/yIY1Rh8G8K7otTG5hK/ITQ2TmOjzHEY1qAUMFYGWMIAjOl/UZOvOsJgdV6Cn/YawLTGe6LLR1eMbXxWgrnC1hIoh/oz9di6xp/GsRik/vidLeXF6N2YBQAU1QueD64L46z8fp2PXwBLNYRR19cn+D5Pzjuh69CoVAoFAqFQqFQuAz4DyIbX8cdR9k5AAAAAElFTkSuQmCC>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAYCAYAAAAs7gcTAAAAiklEQVR4XmNgGAUDASYCcSoSvwOIa5D4YCAOxJeg7Fwg/gXE/6H8s0DcA2WDAUwCBHigfH0gtoCyI5DkGYyQ2GUMqJo5kNgY4BMDqmK8AKRwMbogDAgwQBQoMyDcq4UkfxWJzTCTAaKAE4jPQdmKUDmQJ1dA2WDAyABRAMKuDBAbYPw6JHWjgHwAAGFEHDJYgssXAAAAAElFTkSuQmCC>

[image3]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAYCAYAAADDLGwtAAAAcElEQVR4XmNgGAW0AJZAvAyImaB8EJ2FkIaARCD+j4S9gfgnigoouIPG/w3EgmhiGOAMEEujC6KDR0DMhy6IDj4AMTO6IDr4hi7AAPEUCngCxJ+gEs+B+AqUHYusCMQBBQ0IgMLtLwNEURBcxSggBAD2SxWRkBoDXQAAAABJRU5ErkJggg==>

[image4]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADsAAAAXCAYAAAC1Szf+AAACgUlEQVR4Xu2XS6hNYRTHlwHJo0wMxYhEZgYyIIzcjIjk0fGIDCgpSUrkcU3u5DJhKAMRpUwoeYyURBSFOvIm7+cI63/XWves89/7HNcdnXvbv/p39/f7vm+fs/bZ+/v2FakYsozSvNV81fRS37Djj2ZKOj7a6Bp+PNBM92MUez71FRiveSI28Db1lfFFs5RlBzBa85tlpiZW5Ehv79V87u8tsllsfKcVu1NzRrOdO4KJYl8cVyRAG2nFO+nMYoN7mjpLUFbYGGpnPvnfTiv2aTo+IsWa+oDElQBzxJ7dVqwVu+UBF7tCs0dz0tsTxB6Hbf0j7DHZrznm/Zma5pDmrLdnaE5olsQAZZrmuOZgcgDnzcXdFNuCmsDqhUGnNHc1Y8WW7NKrIrYoBVzsLs0v992ahe4vu1ssje1gmbtJ3gYH3CF1sYs+wtvPNNc083wsjvk79ogVeVHzmvr6WCmND8hgNftJ7o3YhwdcLNjofgt5uMcl7hy55+7z+oHFBm59cgBuFrm2dIlNekn+ivsA4/LtCMqKrbln4JaXuKvk6lKcjwvHDsDNZ9mOyWKT4jkLLrif7W3+lUFZsavdM3C4jdldJ4dfn+fH3cLALWD5LzDpNDnc9/BTvX2Dcsv78daCdrDKPTPQYh+5z2wocWDQxfLzdMd9K3AR0M+/bM0906rYfKFA3X2m3S8bi+CAmSnFk6G9j1xmrtiYTeR3uMd/IAH2bLh1yQG4++TiZSWz21283YFx7rDd/TdbxSbHu/Hh5u4mPmpeiG0HWD3RBt+SfyW2PWA7wzEc+r5r1oit7DH/AyYr770Nj/5FYntlPuclzUOxBTXO+QOTKyoqKiqGAn8BZavHDuPlMQUAAAAASUVORK5CYII=>

[image5]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADsAAAAYCAYAAABEHYUrAAAC5klEQVR4Xu2XS8gOURjHH+ROUe4r5VISKbKjXEKycFsoJVJkIfos3BkhG0tLkuvCxkouRUq5JqVELHwSIinkkvvz75xjnvc/Z753Zt7vZfP+6t+c8z/nmTnPzDkzZ0RatKjCWDYK0J2NEsxh41/xm42CbFZ1ZbMgPVTv2Ww2r1WD2SzIFqmeLFikustms1ihesNmCbZKY8kCzKqhbDYDXGgYmyXYJo0nu1r1hc3OZoRUX6uB7dJ4sqDuOLqJm0Ybfb2/anLaXJfjqm9sEktUh019iGqaqe+QeLJ9VWdUM329n+qE5L+Bkex8NgMHJB3oGNVXcQG4AUX5qTrFpuGYuHMGTRcXY9kp2WTbVLt9+Ynqiuqeqou48wzwbRbkcpFNsFxcUC/j3fdeGdB/L5uGy6aMm4j+GLBll9Qm20f11NQPSjquC6bMPFI9YxMg4FXE+0xe4BobHsSsYjOHt+K+iwyeoE12qimDD5KfoOW8RPot9eZa8uFhSsW4yYYHMSvZjIAlwk80kEh2GltwDazVepyTSLKxqTDaez3JD8xjw4OYPWwS39kgEslPFltJXGMUN0R4qHrH5iHJJnsy4oEHqtvinuwRagP17nrsTc3XSaQ22fWS9tlvygGuBzB7LrGJV7oNwKcBdXQODFK98OXr/oi39yZfDpyW2jjLD3HrFOd+LO58KI+znSSbLPogNpTtWI+qppi6Bf0WsglmSXqiBf6YmHZ7gVv+OEnVbnwwUuJ3GrNggi/jMxGuNf5vj5REapOdKK7vL3HLap+vQ/zyssTGkQG/ZejY23g2MKzXdtUa4wfQdyCbJUgkf80WZZlkvy5Rzkr2roT6DH/ETIh+w5QNqudsliCRxpPFeDvcn+MvAWswTJF1pg0bgDuql6qPqsWmLQbWGLaaVUiksWTxQK6yyQxXzRW395wt8cV9g40O4NlRlESqJ4u4T2xWJW/THQObBuyxy4LtYVWw7e0UyvwQtPjf/AFOe6JzK16zngAAAABJRU5ErkJggg==>

[image6]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADsAAAAYCAYAAABEHYUrAAACvklEQVR4Xu2XTahOQRjHH58pCskVSiGxJFlcS0kWyEcospCFUizslEhZ2Khbutnpls8iWfnmno0IKSxEFpSkfOSb0r08/2bmnuf93zmnmfd+bLy/+nfm+T8zZ+bMe87MvCItWuQyXTWSzUTa2EhkPRvDwUTVGzYzuMJGIhtUJ9gcav6ykclVNjK4r9rC5lDxUrWXzUyusZHJQCc7mcHo6DobmbxSHWNzsOlUfWezCW6wkckqqZn0+arjqkk+Xqy6pFrSVyMNdHCYTcNM1XnVQh/PVp0T17/lJsWWA6p9Jt5pypbow45QPVEtE1fhtZRL+B9Vly+ngPbz2PRclPK+vaqTqtOq8dJ/YLcoDvwWVxd6p1oh1XVRp51NzDT2w9XiKswxuSPeYxaw4UHd0Wwqi1RnTfxQyvv+NOXAbYoB7rHNxFNVn03M4J7b2dzvr/ekf6cXyMNbgA5wxa/OcPvAJopRr24f7maDGKX6yiaBPvBjRUHyWcSzD/BF3IOGHBPzYqDeDjYNBRuGCVI/UQH0cZTNAJKbI95bX8b39oFyDDzMeh34jmJtLQUbHhxBH7BZAfrYwybAh84D2Oq9cT7+Ia5egOsDeHPZVM5IWf+OKQc+UlxQDPCg3eRNUV0mL4A+lrIJ7opLYn8CWLAQ228N8SkvrIA8YADvIJvi/PembNs+Vk02MSgoBmjzyV8xYVgzYmMIVOaQeKF66ss4GMxoqNHY+JGqw8SBLomvkOEt+eZj/BqIsQVh72UKin+Z8jpxbdFP1b+q2JvaBxIYUBVjpbFx1Y1ie2YzFGxkgoV2N5tgjaQNsMdfcYLZaBMEFrSqU00qBRuZVD4PXgckd6mmUc5ySNzfp+WcIMZITWeJFGxkgKPmSjYDGDze8bVS7qEDBWfe52xmULCRCI68WPmHHRzum528WWwkgrezxX/HPwE3pnGlTHl+AAAAAElFTkSuQmCC>

[image7]: <data:image/png;base64,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>

[image8]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACMAAAAYCAYAAABwZEQ3AAAB2ElEQVR4Xu2VzStFQRjGX5RsFAsfWUkhyUqWFMlCyEehlMjOxj9gIxv/gQ3lIzYsbCRK2bGxYUF2EiKJIvIR72Pm3OY+d657zsXOr57OvM+85z0zc+bMEfnnb6hgIwUtbPwWH2yEIFt1z+ZPuVIVsBmSLtU+m+kyqLpmMyJY1SI20wGFitmMyIjqic2olEh6e8VH0jqVqmlVno1rVWuquliGYUH1Qh7To5px4kJVvRMHYDCtbGaoDlRNYhJOVd2271U1Z9vgXbXkxMy8mBqBGsTc4wOT2mRzRZWpahdToMzpm7JeANqTTsxsO+0sMfmYrI9jMROPY9xe9yTxPa6Sh/awE3/HjZhzJRkbkvi8GOg48ng8mCEnTsazJF+RgHVJMZg+j3dB8YQT+8A+CwMmfssmwD+DRzlgvRzHQ7zoxIzvS+O6AVi9LTbBrpib2myMDY24N5ZhWBZTxMebmH2C+05U57Zd5SY5oK+TTRAUOLTtBzEHHFMq/pnOqmpsG2cVcqDqWEYivjpfoAOvJQzIzWczIv2qSzZBh3wzSg9jqjM2I4Lnef9vd2I6RyX8nxT7I5fNkDSqdtgMaBbzNWEzpTobXKKsZgA+jEc2fwMMvJzNFITdl//E8Qk5s2uO8AAgzwAAAABJRU5ErkJggg==>

[image9]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD4AAAAYCAYAAACiNE5vAAACoElEQVR4Xu2XS6hNURzGP/IYKCLF7GIgxiIDE4kBE5RSUgqlGDEwEGMlpmYykWSg6BIDDDCjFN070Y2BRx6RPHMv/8/aq7Pud/977bUP9yidX3119vdfr73X63+APn3asNP0s5LHDNM8NXvEBjVKWGbapKZwCJ2X/iixyA81egg/+gc1m8jNYoTx3GyOmqaqaaw1DSPUPyextrw1jaEzXvY5ksS3mO4nz1nmo/nFF5huqplwxnRZTeMgwkAj+5Dvp4TVCG2c1kAFYxxvIwcQligrHJVY5IppQM2Eupehv9zxjovXhmsIbczVQMVu0xc1Pe6aViI/63U+2QY/vhm+/w2+X0punJGm+G9iobh3PLi36nhmuqMmwtbw2huB75fCuk2HKMtsVFOJg9hf/T6SxKK/R7wU1tmrpvEe/gs+hu+XsAqh7gkNCN9N19VMWWJ6kDx7y4gvkIPl16kJvy3yEL5fwlWEurM1IPAWeapmCg+KFcnzV4SGpyVe0yAZX6ym8Rx+3Ufw/RLqPqYSD8BaNLi+8uIymWW61wm7sPwiNVG/x5/A90tgPd7dTQwi0weTDS/TSb/qSfjLOIVlmaQoPCu8zrs91ePNc0oDDkOmd2pGLprWqGmcReiACUKafNTBsrw7PRjTbI8e84KUY/LsEWdR2/Pglr2hJq+mmP3UEWc9VybCvXxLzYqXGJ9SLkRoc3riXao8Hlw5SsdDWI55xAST2qqBhHi1NQ2G7EJ+QG9Mr9A5kXmTpHAGX1cxj08IW5ITxuXLP0ifx5WYiNvWBdNhNR3qUkIPt6OWeOdNN2w3vVBzsuByPa9mC5aadqjZJZwEbqme8SezXnKIlsDb5baak81MFP4rcpiiRhfweuZ58E9gKjlHzR7xt7ZKn/+CX6vLumYriXYqAAAAAElFTkSuQmCC>

[image10]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAYCAYAAADOMhxqAAAAxElEQVR4XtWQOwoCQRBE21gMDTT2GIIopt5FMDEQBDMxVQ/hKfwlnkED76AY+atiZ4fZ2lmN90FB82a6Z2izUlFDlshID2JskIWrW8gnOMsxRtri2DAR5zmrsKRhppKskapKSxoqKkn61zrScfUzqHPskIYljQwv3zM3AnoWn8TGqUqyV+HYIg+VpGjXb+SmkpxUODhopbKPXFSCoRW8fERelt01F8DLzcB50ilXVzNzfxqhaENR+P+uyl8cVPxjoKJkfAEDOycZaGYRWwAAAABJRU5ErkJggg==>

[image11]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAXCAYAAAA/ZK6/AAAAoElEQVR4XmNgGHJAEoinAjEbugQ2YAHE/4A4Boj/o8lhBSBFPVCaaA2a6IK4QDgDkaYqA7EXEJ9ggGjwBWIPFBVowB+IixggikEeBrELUFTgACANa9AF8QGQBh90QVwgjYFID8MAzMNEA5DiN+iC+ABIQzO6IC7AxADRwIEugQ4cgdgPiJMYiHQ/SNEHIL4HxKVoclgBSMMuIL6OLjEEAABbmSIQUKWkPQAAAABJRU5ErkJggg==>

[image12]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEwAAAAXCAYAAACh3qkfAAACFElEQVR4Xu2WO0seQRSGD4IK8QJewIBRi2hQSCdWNv4B/4A/wNpeC+uQyk6QtFaCnWCRxsJCsEkRwUq8ICJRwUvQoDkvO8M337v7fTOzggsyD7w4e2bR47OzMyuSSCQS748RzQsXKwA99HHxjVnR/OIig0arFrYu1Qv7IFkPTYVta+6kWmG9miOpXtizeIR90mxqLiVc2BwXiFZNFxc94G9/NT9DhLVoerhIzHPBw3fNlHiEWUkxwgY0N1w0dGgeuejhh2Zc4oSBW8l6KeJUM8rFJrRrDsy4obANzZAZxwgDWJlo2AWynqjmo1OzZ8axwsC9ZpBqZ5I9gBjcvguFoamfznWsMADZ2PsAZP1z5kLBnmEpIwy40iBrwpkLYUkz41wXCmM5ZYQBK62MrG+aSee6rDAAaZCF3xED9kIcNi45YauSX7JlheF0w3J+4AkPbZrfVHuNsD+aa80wT3iwb4hLTtiWZoeCmxCM12q3NsXKAv2SPeVQxiTfw6FkPeya61Agyy4ASMP+Ggr3YF1AJMbTtVvrscJCwZHOGzykFT2xUPAZELvCXFkWSOODIIbcCisiRli35i8XDZDGp2coi5L18IUnGoBt5DMXDVeaj1wMBD2ccNGyrznXHJtgbI/5RixwgcBHK8SFgtWKfx5Nogd8QzX6zrNgD/S9estc8IC3AwcHekAvF5rZujsSiUQikUg4/AeDSY9IIgssCAAAAABJRU5ErkJggg==>

[image13]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACUAAAAXCAYAAACMLIalAAABlElEQVR4Xu2UOy8FQRTHj7fQ0opH4dH6AnS+g0LhA3gkJEKiQKFRoFGISDSiUEn4CApRKCiJCJEgIUiIx3/u2d175uzM3CWSq9hf8sud/c/JzLk7u0uUk1ALb+ETXFFzZeMLtorxanGqfJzC7mhsmtoVcwljcBv2RNddcAuOJhU21fBNh4Jh+Ey84b6ak9TDTx3GzBMvID22KpgzsmtcHMGhaFxFxdq6pIKZhDvEN8TJLFyGm3CGeLEQj+RuqhK+wxaRNRLX+u7sCTzXocE00q/DAL6mBsh9F3V2IcaLlK4vME1/05RhHbapTDZVI8aGQ+JPQ4opuEBcvBH9rlkVNqGmNA3EtZciWyJuZg/eiNxiHB6ozCw0p7KYnzT1QtlrS6KfA0nWpkaI60q9OE4qdAA+yL9xlqZ6KfANyoLZ4M6R+TYu1VQTfFWZfKYyYTaYcGS+jUNNmaN60CH5672Yh7FZXPcRL9IpMkno4Y3/jPZXR2mOTy7Sbk8XMN+Ta+KjMF7Be9gRzQ9SuplY/Xbn5OT8O74Brn5/Dgm4hS0AAAAASUVORK5CYII=>

[image14]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACUAAAAXCAYAAACMLIalAAABvElEQVR4Xu2VvSuHURTHT0QWLMqgZJHEYrQpxWayWC3yTsnCalCyIJvBolAYEP+AJJMki4jBy2BQlLydb/fe5zn3dK+fl4Hh+dS3557vOc99zu9373MfooyEQtYt64E1o3J/xjurSoxn09TfccKqtWM0tSZyQUZY3doU7JKZ6J7VqXKOGjJLg7pDVr6fTihivWnTscR6JjMJ1OOnE5ArsOMOG2NvSCpZeyIuJlNXKjwwylphDSs/SKypbda68jbJ1LcJD7Gmj3WqTcsR61ybmlhTL2Ry7cKrs96N8BA3iBgMkv/gCzGepPAP8Yg1VcFaVF4TpfvG4baAfKMQl9gxll82sU9m/31KrKkQO2Tq64VXbj2nV1a1yINpMs1g+a9VLggm6tVmALxRqD3QCaaR/MY2/PT3wST92gzwRP6yOcYp3TNdlDa2kFT8AEwwoE3FMWtZm5T+e5pHCvtfBjcPaVOwyppQ3qW9zomx5tdNxQ40HHj6tMfGRjMA98UeHvNzUkbm5imdYJrJ37xSraIOcYuIwRZrXnk5wXF/x7oi8/fjigMRnx6HbkQqT9The4ZjAP6ZvY6JfEZGxr/lA2pxfzdAAxeMAAAAAElFTkSuQmCC>

[image15]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAXCAYAAADpwXTaAAAAVUlEQVR4XmNgGAWjgKpgL7oAJeAfugAlwAaIy9AFKQHngNgcXRAETMjEt4B4HwMa8CMTX4NiFgYKwUQg9kYXJAcoAnEnuiC54BO6ACXgMLrAKBhuAACnlhESw2iRqwAAAABJRU5ErkJggg==>

[image16]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAARMAAAAXCAYAAAAoT6saAAAJcElEQVR4Xu2bCYwmRRXHH7KILCh4cKus4AGCukpAFAEBOUWUGwLIBgmEKKCgoEJkUANGwymi3IhyihjlhsAuR/AComgUPBbCIQgoKuDFofXbqjff+95X1d3f7LDTM9O/5GW++ld1dXe96uqqVz0iHR0dHR0dHR0dzXifF6Ygs73QkBW8sIiZDr5pwppe6Ggf/wy2mBenAK+RwQ74P5duwliOGS/G4hvu+81enGS8NNjaTrsj2Nuc1hF4ebA/Suyod7m8HP8ItpMXx4Fbgm3ixRbxRLDfeLGGjSW2K3aTy3tDsCedVsXiwa7woqMtvtlKevd9pcubTDwjvfvwoC3txRaxnOSv2zIr2KMSy/2oP2t45kisaImUPjrY30dzBzlAYvnx7rA8WHU3vijgzftNLyZKnaoJucEE6Kwf8mKBC4Mt5UVDG30z2QcTOEfy97+lRP+1ieWDPSC9vpq7buVbwZ416cuDXWfSQ8GJOdnLjFZ3AY/Li9NheUPv4MUJ4MNSHkxop5d4sSGlweRNUt3elrpybfTNVBhMTpNy26Ov6sWWUPUsby6DeaT/5rTG5E4206UteqIXo8P665gonpLyYLIwlAYTIK+q3eH1wb7qRUNbfTMVBpNTpNwGxE5u82JLyD3fCvrvnbaSSw8FFf4q/X6PxNhJiY9KXBKB77CbSTz+3dKL9m8Y7F3B3h5sg6SV2FfKN801XRJsfrDDg3036WsE+4RER+8lccZwcMrnwfPMkPgw0oDzgr2lLzfCMoLruDrYtsmU3YN9QXrnt4wE+2WwHwfbtD9rlLrBpGqggN96wVDlmy2CvVeib/gLbw22rkTfrJe0ElW+AeI4J0ucFfFQ+UClHUy2D3ZxsK172aPU+YdA7oHBTkx/gbgM9W2jhRK7BTsq2HdSmtjB0cG+MlpikE8H+1Owb/gMifdXagP6RSlvoikNJq+QqH89pWlHDXMo9GOeYfoNzzZLXQLR9Bf6Dc/2Klp4LYkVXiDxQSCQdGrSchDYU3yH/YzEzo5+T9JGUvr5YOcmrcTPgj3sxcBrg/3LpF8pvetjgPpeSrNuvTTYkhIj7GjckwWNtSTQcKTtw03jHZr029NvTBlJeb59SP/XpR8yacWfz3J9sP940UE7lqjyzWHBbki6Bnt5+PRevp+0EiXfAD6gDh1A90tpu31NmsFZ255BAc3P/ur8s3qwM5N+hgzWZweBzwb7d9IZQJjSg7aDhT6DtndKM+CStg9X1WACVXkTifrYw2CM/rlgl0l89udJfz/eX3r3jdEuxOs0/ROJY8gC9jAZlhek/wGGP0v/liDH5KbSBG61Phz4A5NXBee81YsSB4s/OM0Hhzkf5Sx0bnRmLArpq0z640nzoPmOrpwrg8c8F+wxk+bNTBm/bEErDSYEwny9lu2k19k9TX1zp/TOsaLE3bsmlHwD1Gfzdk2ahbTXbD9RhvGP13P16cCmsxgFbX2TZrvbB1HxKTMtZTwGE2bYzJRydn6wb0vsX+cEO0viwLmw5NoKTpd8Hmn/Et456Trb98cs4IMSM5jaWejw9gDKsXywkJ/rsEAe013voCo4hsb06PYib+0vSZyZeErH5hrLwvXn8tFKgwlvv9wxltdJLOM/SkMrDSZHSHW9fnBXxuIbDdI2pdS+Or3XpVMJytznNAbAumuo8k+T+uZkNECzyyy9PwZYNXY07LFNBhO7idEWuK7cdX9Nos6y3sLsN1eeUAg6W8jMYgZYTWIBXVcq7DWj61o615HJL3VY1uPkl2IHOSh/nhcTeuNq/jsPtFxn9w3JupkBjjftF4Md4vIVNGYKOXKBOGI1uk/Pep4YBb/faQslba7TFJaJvl6LH/CVYX3DbIn8EadXQfnzvCjxexfy7KwoR85nLAP9/Q7jnyb1MSv1GqBpjOWNKU0c7AMZU5oMJlXxxomC68pd9z4S9Y85neVyrjygM2gXoQDBTQtTTXT9apFprDWi1+QTI8lNf38qcWZSuqgcrG9v9mJgWfObh5a4CPW+3+ik6wYTpmj8Pr6XvSBQnLtGtLPTb7Zt7VvMd6oZKU2MxYJGgMprc52mMBPKXQt8Ptg7vJgY1jcMdtdILJOb5eUo+eZYifWs4TMclLnbaQ8mXRnWP3X1wZ4ZDdBsYJ00g0kV3u+eqjyF2AwB5mFsYeG6ctfGc4Xul4AM5rnys6Q3OyFQnYVMH5P4RdJLMMiQn3v77Sa9B5E3TF1QUWGdRofwzJXBnSCCRDxgCtfiBxP98u+HKa1f91o+YjSbx2/WsMBDzA6EQvTbluVefb167nWD3W90tNxDCddKXLvn8PVXUeUbBsZfp9+PSfN6S74B6mCAtzBTYaBRKKPnVfxMYlj/1NUHczIaoLE8tOlccPt+87tqsIeqvImE6ypdGzqxGa/lyqvGjJHf9iU/yjoyeDDpY5xmYbuIMkR7LWzF2brYRiLNV3V1UJe/Dpgng1N5yi3v0tjiRvNrP97IpF9lND3u1emv1f+SfrPtyOxDuUj6y/KBG2kbN9BdBB5oO5ii+eCWQt5JXpR4bnYgmlLyjQbb8YlC2n9nkKPkGzhBYh5BZ4V7tL4g3w9GfBNj6xzWP3X1wWFJs/c8M2n7GI0YCZrdNiZWd6RJM3v39Sul2E4b0DbMkdvyJ725SevLiU8yFK3TPhejHCQxU98Ox/Vn98HWItuEOJO3gW41EtRDI3agUehngz1i9LoYir8xmCcxdsNDqTdhbxbQmJmwxallctudGjzFfpc03qo8/GxBK0z/tZztYE9LjF1w37zZdXr/SemVp1OzpcjMiZkZ98zam7Um7cDx7Dx4ODa37Lgw2DJeLFDyzV9TGl/cmzSWQfhEfTOS9BI53ygaJMe4N7YPgX8R0Pvm/DpA85c0Ou2o3yXV+WeY+vCVtgX3zYyQQU77I3l2g4ABZ770zv8pk4dPqR/j/PjbcrvE74vaBNdMX+Netd+heTQGqM/+LiaPdqedOFbbipcSbUxboDddeSxyuBmCl8PCcX6ZM5ngQSk9rCV9UTNW30wHaBv7TUpHC5gt8W0+LDhTYxyTEWYQO3oxsLKMTxBuPBirb6Y6LCvth14dLYKpEx23CQQ4vyy96TWf1k82WK+zzMjxcy9MMMP4ZrpAbC4bO+hoB7nIeo61gm0kcbeH/x2YjNPwqmUMMae20dQ304EbZfBboo4WUhesnQps7AXHql5oCdPBN02o+/K3o6Ojo2MY/g+/MTCXPRwsAQAAAABJRU5ErkJggg==>

[image17]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD8AAAAYCAYAAABN9iVRAAACjklEQVR4Xu2Xy6uNURjGH/dLKZwMKAO5JEpRDpm45JaJkSiDQygZidJB+QOUREJKMjIwUJJIhhQGlOSeSHIZSBggl/fZa62z136++3dGe9u/etrrfd51+S7rW2ttoEuXmNVqtCmTTUPVzGOnqV/NNuavGllMNb1Ts80ZafqjZhp8SqPV7ABum46oGbPE9EPNDmEYCqb/L3TWt67w5leqGWByjJoR60xnTON9vMF0Hu6pVmGe6YJpgvjD0ey7CtNMF03jIu9UVA48Md1Vk7Bh3rT4buqBWzxY75pphWmpj8vCNvz20toxfileEbPh2gVtMb1F+vZ2AMkxGyxHRsK4ZJobxaz3MSr/jnJFhDHOReUA413iFfFeYr7d+eIFNiE5ZoOtyEjAPbEY1tvuy1Wn/DL/yz6eRv4C7w2JvKqcRbP/NBYh4x77kJEQelGuXh5j4fqIZ9MV79XlpmmOmsJCZIyxGBkJ4TrK1cvjGJJ9MP4sXlkemiapmcJGJMdtwJU3NQH3fb/2Zdb5EOWmILk9HpJYeYzkWIz3iMddYZV4ygu4mRTzSeIAr1PHHYAJruYK/ZOmmb78SnIxXBzpXRU/5gRa293xsa7Q9LT/GI7BswnrfDXd8mV++2lwhjxQM8CGe9WEOxoyx84JpyfjNwM1mkyEe/J5F00eoXlz9/2vchpulnAfV2bBnTECX+D6yJt1zK9RM7DP9E3NmvBisuDKHsOL4iEljcOmEWrWgLtI2gNugRV40hoMfCub1fTcQ+tFHJVY+alGTW6YjquprDU9V7MieX8fn5n2+/I2uBvPOischDsJDhauJaUPYpxqO9SsQNFBZbfpsmm9JoQZatSk9I0H+tRoU6abRqnZ5X/nHwN9lKczlf6zAAAAAElFTkSuQmCC>

[image18]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAZCAYAAAABmx/yAAAApklEQVR4XmNgGAWjAAhmAPF9IP4PxIxI4gVA/AeJD5LfCePoAnE5kkQ6TALKf4XGB2Ew+AGljaGCLDAJKD8PiR8BxGdgnFoo3c2AZBoQMEH5IBfBgAYQT0XigwFI0UskPsgmZINAoAGIxdDEwIrCkPgvoGLI4C8an4GbAVMRiP8MTQweosgApLACyhaH8pENu4/ERgGwUAXhh1CxO0hiwlCxUTD4AADh0Sp0gvlmIgAAAABJRU5ErkJggg==>

[image19]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKIAAAAYCAYAAAB5oyYIAAAE+klEQVR4Xu2aaai1UxTHl3kmlHk4ZMyYoQypN58MSfQiRS+JD6YShaQu8gFfZMwYHwzJPBSl3iuZI5KZhMhM5pn1e/dePf+zn3Pee+6599zr9O5frc5eaz/72eOz9tr7XrNKpVKpVCqVSqVSqVQqyx7/uuxX2FZx+cll7cJeqYyUC13+dNmosC92ed9lucJe+R9wk8uJpdHpSPosl3VFHxcecPncZUWxreDymcsjYhuGK1zOLY3O7pI+2mVn0St9+MPSxLCdHSh2JgobRP4PTfbY8a7LM4VtA0te85LCPgh/uaxjaVwuFvtd2RaQVr3SgzstLTJgsBY0WUv0+0V/yeVH0ceRNS3FiVcX9n0s9feIwt6PU1x2ymnKTTRZS/SvRb8q2ypLgTgK2GJ0sJbP+i5i28HlWpfdXL6ytncZhPCs8832ltpxTGE/2eUfl80Ke8mi/HuotfuDfkZheyP/vmrt54flHpu9d42SVV3etAHbykNfiH5mtikTlrYyOMqGW4jwVGmYB7awtOCIe5VjLfV70JiOHULHades60FogaXxCspxnQmz+a5Rwk3FQG3lIYLqgOC+LPi3pNnChl2I8wkHli+tfUjZ1lJ/Ty/sU0GZ60S/O9sUvKBS5s+E2XzXKCEkmrKta1j7IXQOK8oTki4X4jUut7t84nJktp3qcr3LjZa8D/BerWslSzHb2S6/WHOyjeeIw9iCOFCsl/OGZbHLB9btrdg2vnW5WWzTgTYSXwbfZJui8SKQz+IkzKHv0Z5NLW3h57v86rJytgN1EA5dZKlMEHXdm9NaNx8cB6f3XB7Meb/n34NdXrMmtuWK62NLNwCUC/Sdj+X0eUVevzk6yJJDo27mtxyXnmgFG2ZdC34oadCFSKeYzCDKaXldtGovG1fmnZbTB1ha5MNwpaVFXl5ksxheLGzThTY+ntMRV2sfOOytJTpofpy6gYl7MqfZ4lk0wILUMtxyBGHnQ9pK7HhpFjRc6nKf5FGeWwJi/v2zTd+/msv3omseO0msE+g3R3xU3CoE21h7rnuypzWD+FG2cekbtvWzLWAhPpvTVM61Dr9IVPhQTtMgBjaIfA4EZePQmdBIB3u7/Cb6ICyy9I443QZ4br56vPFMwZPgCagnPNVk1hEOdiW9+hzwvjtcPhX75dYsyhKemcyi8AHcltOXWff1FOO4nejH2dLbpOmHrb0QA50jvGd8oNCxdh2zAgvxuZx+y9I2UxIHG06mvTq2eWEH9NUlHexh01uIlI0QIWAb5qPYpLDPNb36DI9aOl2CxlQT1u1dlHiG0AcPFxDiTFry+O+IHRjHjujHW/82lWnaGJ4W+s3R89Z4d+hYu45ZgYPNCzlNjKkHmZPyr1asJ+V+neRqJ2JJ0Ly9rHtLGme0X3wU4Umxb5nTC7N+g+QFfMB8VGrn49VnznHZWnQFD17maVkObhrXlvMVV36hBzpHHeuey8NtBAuRQfrOUlwY23PHUgfxjvtmG1s7HcLGPSUQq2HTv9C87fK6paA2+NnSc8QquHzq4yBA+XGH3YQ/DjxtjQcEtmW24Jct/YWL67S4eMdDMt6vWPOnWK6OYiyJ02NOCAc2tjTxKoQijB/jyLO3WAMLuZyrgN2OemnrrZbedYFNPUeHWWoP4doh1rSjsgxRTjj3piyySmVO4ZbiBNHxsuW/xVUqc8aO1r4+qlQqvfgPQ5hvJNGlpoAAAAAASUVORK5CYII=>

[image20]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAXCAYAAADpwXTaAAAAjklEQVR4XmNgGAWjgGjAAsST0AXRwF50AVxgFboAFvANXQAbYATiZ+iCWIA6EJehC6KDv+gCeMBSIDZHFwSBBCD+D8QmJOJrQLyPAQ1UMkAM8yMRgwwDYVCkYYA/6AJ4wEQg9kYXRAYgG+6iC2IBikDciS6IDWxBF8ACPqEL4AJsQNyPLogGDqMLjILhBgAQJRjl3POdFQAAAABJRU5ErkJggg==>

[image21]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKAAAAAYCAYAAAB9VvY1AAADn0lEQVR4Xu2aS6hOURTHl7fkkVcpDNy8QmJgYIKSgVdJmEhdyUQGEiNhhogkRURXYkCKiYGSKAMSA28JyauQV5G39W9/x93f/57nPcf5znb3r/7dc9ba31n7sc65e+9zRDwej8dTfeaoxrPRU0kWqUaz0VXeqX6rFrDDU1kmqU6JGbd15HOKFjGN8LjJUnF8/K6L4w3o4DSJ4+N3WxxvQAdnuJjx68wOV3ggPgFdZoiY8evGjiimqo5La8bi76pWd+k8luQEHKE6qepj2fZZx0VQRoyqUGQODBYzfj3YEcZyMYUDzVV9rStRPs8lPgHHSn2dm1XPpNhHfhkxqkLROdBfzHV6syOMh3T+XcwFkjgaoyNiVrKHVYdUByXl3VADlcdCJIpXdH5PNZlseSkjRlVobw7EgTHcw8YkrqmGsrEkuqiWqH6pLpEvDiT4DDYq81Tb2dhOwmJsE9PJb1V9yecyUTmwW0x7cWPuJV8Y6BOUv6yaQr5QnkpjO7Knao2YSrfUuyI5rxpHtgGqtaorUkwChsXYqOpaOx4jps7/A0k5gHb2Y2ME+I+HZMWCcj752vBezBMoCxjcLIprGIOGXmAjcVPMZDeKi5I/AaNiPFL9sM5RXzxxXSYpB7pLthsNZQ+wMYzPbJBsgf4FryW+Dpiz9CIbfmMTl4ATVbPYSKSJEYC6DiRbmhib2UDMVI1iI7GBDcRsSX6XniYH8NTH3DANqRchWNV9FFP4pepW7XiZXagBYPC5AwLOiukI+D+JmWPgGPM0GyTgDrIFoHzU9UHaGOCYhC+YkmKcFuM/wQ6LpGsEuwXr2VGjkyRfI20OIEkx701DsA0Tuw+IAFh+A2wt/BTzo4V/SzSO+xLeafjSAivsgA9iym2ybAFIwJ1srLFfdVfMPh+TJcYEiV4wxcUAeEoggeKmJi0S/RQH2Cp6wkbijESXyZIDsHNdkbxhBBvRuAGc5I6EJ2AWkIC72GiBgY29QxPAZNxO1GnWcUDeGEVxlQ0ZwQKRxwPJtZJsAcOkbXmnuCH5G4AExNZBFN/YkAF0Pt5XN6tWiNnvCtugzhOjSPL25RYxT0cbbJdF0ST5YzaU4Juy9oI5Dfbn3oiZwzGYuE9nYwaCOZMtJm+MojinGsTGDOAmQrLZbUUyvrALEfgwNaxPnAKN/KJazI4CGMmGf0AZMdKQtIouEsz98K4cybeVfE6CjwDwdgQvyj3VZ7W03bT3eDweTx1/AHFE9qQgsixqAAAAAElFTkSuQmCC>

[image22]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAYCAYAAAAYl8YPAAAAxklEQVR4XmNgGAWjgP7AEoiXATETlA+isxDSxINEIP6PhL2B+CeKChLAHTT+byAWRBMjC5wBYml0QSCYwABx9QsgnoImhxU8AmI+dEEkADKMH10QG/gAxMzogkiAjQFiGEHwDV2AAVNjLQMkLPGCJ0D8iQGi+TkQX4GyY5EVMUAs7EATQwEgDaBkAQKgdPWXAWJQEFwFAoDE0cMT5BCSAQcDprcZgTgVTYwo0MYAcTUy+IfGJwr8YoBoRM4hIIOfISsaBaQDAJCvKlzpGuGDAAAAAElFTkSuQmCC>

[image23]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAYCAYAAAAcYhYyAAAArklEQVR4XmNgGAWjgHRgCcTLgJgJygfRWQhpwiARiP8jYW8g/omigghwB43/G4gF0cRIAmeAWBpdkAHiNS90QWzgERDzoYnZAHE6A8SbBA35AMTM6IJIgKAh39AFGCCa0Pk4DXkCxJ8YIIqeA/EVKDsWWRFUDBRrGACkEBS9IABKF38ZIIqD4CoQACTuiy5IKgAZ4ocuSCoAGRKALkgssALij0D8Foq/okqPAnQAACWII+/cVctgAAAAAElFTkSuQmCC>

[image24]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAXCAYAAABu8J3cAAABVElEQVR4Xu2VOy9FURCFxzNClGqdkGhFxA9QKFUaUVHxF0TlD/gHotBKtBqtCFFoqDwSUXg0Osy6M1v2WWf2vZ7d+ZKVe2btufus/UiOSEPD9xhWXaneVSc0FvGiWmDztyyLBejzekP1/DlaZ1Ws/0+DjIhNOpB5qKESD/IPQaKXDlKd8+S/pSDTbASMswEw4bk/z4jdlRJLYscISkF6VW9sZvCiW0yIDeyqzlRDqm33InBBE6UgoF/iOSKvxaLER4MVvZJ3r+rK6nZBAIfhd1SYF2u4I//Q/QT61rMadAoCUhgoX0SNUbGmHfL33Z/ymncHfCVIt8Q7HoKmPfIO3B/z+oh07OMXXkekEKAney6ChkvyTt0vgYDtdgTHwP/vGGZS6g2oN8nLmRXrWeEBh+dL5LsUsibWkL41W9XhCo+qW9W16sbrnDmqGexWunsNDQ0/4gNAQVvrGYR9fwAAAABJRU5ErkJggg==>