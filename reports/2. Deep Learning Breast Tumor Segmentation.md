# **Deep Learning-Based Tumor Segmentation in Breast Imaging: A State-of-the-Art Review for Physics in Medicine & Biology**

## **1\. Introduction**

The quantitative analysis of breast cancer imaging has undergone a paradigm shift over the last decade, transitioning from subjective visual assessment to objective, high-throughput computational interrogation—a field now broadly recognized as radiomics. At the heart of this transition lies the task of segmentation: the precise, voxel-level delineation of pathological lesions from background fibroglandular tissue. For medical physicists and biomedical engineers, segmentation is not merely an image processing step; it is the foundational prerequisite for extracting reliable biomarkers, calculating tumor burden, planning radiotherapy (RT) dose distributions, and monitoring therapeutic response.1

However, the physical heterogeneity of breast imaging modalities—ranging from the projectional superposition of X-ray mammography to the multiparametric signal of Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) and the acoustic impedance maps of Ultrasound (US)—imposes unique constraints on segmentation algorithms. Recently, dedicated Spiral Breast Computed Tomography (SBCT), particularly utilizing photon-counting detector technology, has emerged as a modality capable of isotropic, high-resolution 3D imaging without the tissue overlap inherent to mammography or the geometric distortion of compression.2 As researchers look to publish in high-impact journals such as *Physics in Medicine & Biology*, understanding the interplay between these physical acquisition parameters and the architectural inductive biases of Deep Learning (DL) models is paramount.

This report provides a comprehensive, critical review of deep learning-based breast lesion segmentation from 2020 to 2025\. It moves beyond simple performance metrics to analyze the methodological rigors required for medical physics applications. Specifically, it addresses the pervasive "small dataset" challenge (N \< 50), where physical limitations or prototype status restrict data availability; the "small target" problem, where lesions occupy negligible volumetric fractions; and the "label noise" problem, where the ground truth itself is subject to inter-observer variability. By synthesizing evidence from over 100 recent studies, this document delineates the current state-of-the-art, offering a roadmap for developing robust, clinically translatable segmentation models for SBCT and beyond.

## **2\. Modality-Specific Landscapes: Architectures and Performance Benchmarks (2020–2025)**

The evolution of DL architectures in breast imaging has followed a trajectory from standard Convolutional Neural Networks (CNNs) to increasingly complex hybrid systems integrating Vision Transformers (ViTs) and attention mechanisms. However, the efficacy of these architectures is inextricably linked to the physics of the imaging modality.

### **2.1 Spiral Breast Computed Tomography (SBCT): The Frontier of Isotropic Segmentation**

Spiral Breast CT represents a distinct frontier in breast imaging. Unlike whole-body CT, SBCT utilizes a dedicated gantry where the patient lies prone, and the detector rotates around the pendent breast. This geometry eliminates chest wall motion artifacts and compression-induced deformation, but introduces challenges related to variable field-of-view (FOV) and beam hardening.2

#### **2.1.1 Mass and Lesion Segmentation in SBCT**

Research in SBCT segmentation is relatively nascent compared to MRI, primarily due to the limited installation base of these systems (e.g., the nu:view scanner by AB-CT, Erlangen). The seminal work in this domain during the review period is the study by Shim et al. (2020), which established the first deep learning benchmarks for mass segmentation in photon-counting SBCT.2

* **Methodological Adaptation:** Due to the high dimensionality of isotropic 3D volumes (often ![][image1] or larger), Shim et al. adopted a 2D U-Net approach, processing the volume as a stack of slices. This decision was driven by computational constraints and the need to maximize the utility of a small dataset (N=93 masses) via slice-based augmentation.  
* **Performance Metrics:** The network achieved a **Conformity Coefficient of 0.85 ± 0.06**. In the context of segmentation, the Conformity Coefficient is a stricter metric than the Dice Similarity Coefficient (DSC), providing a rigorous assessment of volumetric overlap. Crucially, the DL model outperformed the inter-observer agreement of four human radiologists, who achieved a Conformity of only 0.78 ± 0.03.2  
* **Physics-Based Rationale:** The success of the U-Net in this domain is attributed to the high isotropic resolution (0.273 mm voxel size) provided by the photon-counting detectors, which creates distinct edge profiles for masses compared to the "smearing" often seen in conventional energy-integrating detectors.2

#### **2.1.2 Tissue Component Segmentation and Density**

Beyond focal lesions, the segmentation of fibroglandular tissue (FGT) in SBCT is critical for accurate breast density quantification—a major risk factor for cancer. Shim et al. (2022) extended their work to fully automated breast segmentation using seeded watershed and region growing algorithms, achieving Dice scores of **0.94** for skin and **0.90–0.97** for overall tissue components.4 This high performance suggests that for high-contrast boundaries (like skin-air or adipose-glandular interfaces), classical computer vision techniques or lightweight DL models may suffice, whereas malignant lesions with spiculated margins require the complex feature extraction capabilities of deep CNNs.

Recent work by Weber et al. (2024) further characterized the physical basis for segmentation in non-contrast SBCT, demonstrating that malignant lesions exhibit significantly higher Hounsfield Units (median \~60-62 HU) compared to cysts (\~35-40 HU) and dense tissue (\~28-33 HU).5 This density discrimination (AUC \> 0.92) provides a strong physical prior that future segmentation networks could incorporate as an additional input channel or loss term.

### **2.2 Dynamic Contrast-Enhanced MRI (DCE-MRI): The Volumetric Standard**

DCE-MRI serves as the gold standard for sensitivity, providing 4D data (3D space \+ time). The challenge in MRI segmentation lies not in contrast—tumors enhance avidly—but in the "wash-in/wash-out" kinetics and the presence of background parenchymal enhancement (BPE) which mimics tumor signal.

#### **2.2.1 Architectures: 3D U-Net and nnU-Net**

Given the volumetric nature of MRI, 3D U-Net variants have become the dominant architecture. The **nnU-Net** (no-new-U-Net) framework, which automates the configuration of U-Net hyperparameters based on dataset fingerprinting, has shown exceptional performance. Studies utilizing nnU-Net for breast tumor segmentation in DCE-MRI have reported Dice scores ranging from **0.80 to 0.93**, often surpassing custom-designed architectures by simply optimizing preprocessing (resampling, normalization) and training schedules.6

* **Hybrid Models:** To capture the temporal evolution of contrast enhancement, researchers have proposed architectures like **UnetTransCNN**, which integrates Transformer blocks to model long-range dependencies across the temporal dimension.8 This allows the network to distinguish between a tumor (rapid wash-in/wash-out) and BPE (progressive enhancement), achieving Dice gains of \~6% in challenging regions compared to standard CNNs.  
* **Performance Benchmarks:** In the "Multisite Breast DCE-MRI Dataset" (MAMA-MIA), which aggregates diverse acquisition protocols, robust U-Net models achieve Dice scores of **0.87 ± 0.14**.9 However, performance drops significantly (to \~0.72) when models are tested on external datasets with different magnet strengths (1.5T vs 3.0T), highlighting the domain shift problem.1

### **2.3 Breast Ultrasound (US): Managing Acoustic Uncertainty**

Ultrasound images are plagued by speckle noise, low contrast, and acoustic shadowing, making lesion boundaries "fuzzy" and ill-defined. This modality benefits most from architectures designed to capture global context and refine boundaries.

#### **2.3.1 Transformers and Attention**

Pure CNNs often fail in US segmentation because the local texture of a tumor can be indistinguishable from shadowing artifacts. Vision Transformers (ViTs) have emerged as a powerful solution.

* **Swin-Net:** A Swin Transformer-based network proposed by Zhu et al. (2024) utilizes shifted window attention to model global semantic relationships, achieving a Dice score of **0.818** on the BUSI dataset, an improvement of \~1.4% over CNN counterparts like CPF-Net.10  
* **Multi-Scale Fusion:** The **MF U-Net** incorporates a multi-scale dilated convolution module to handle the extreme size variation of US lesions. By capturing features at multiple receptive fields, it reported a state-of-the-art Dice score of **0.9535** on the BUSIS benchmark.11  
* **Performance Range:** Generally, "good" performance in breast US segmentation is considered a Dice score \> **0.80**. Scores exceeding 0.90 are typically observed only on curated datasets with high-quality images and clear lesions.12

### **2.4 Mammography: The Challenge of Superposition**

Mammography presents a unique 2D segmentation problem where 3D structures are projected onto a plane, leading to tissue overlap. The primary targets are masses and microcalcifications.

* **ARF-Net:** The Adaptive Receptive Field Network (ARF-Net) addresses the scale issue in mammography (lesions range from millimeters to centimeters). By dynamically adjusting the receptive field, ARF-Net achieved Dice scores of **0.86** on the INbreast dataset and **0.8575** on CBIS-DDSM.13  
* **Transfer Learning:** Due to the high resolution required to detect microcalcifications (often \>10MP images), training from scratch is computationally prohibitive. Transfer learning from ImageNet (using ResNet or EfficientNet backbones) is standard, raising IoU scores to \~0.90 in some studies.14

### **2.5 Summary of Comparative Performance**

The following table summarizes the key performance metrics and architectures across modalities, synthesizing data from the reviewed period.

| Modality | Key Architecture | Dataset (Size) | "Good" Dice/Metric | Primary Challenge | Reference |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Spiral Breast CT** | 2D U-Net | Private (N=93 masses) | Conformity: 0.85 | Small Data, 3D Volume | 2 |
| **Spiral Breast CT** | Watershed/Region Growing | Private (N=17) | Dice: 0.94 (Tissues) | Tissue Differentiation | 4 |
| **Ultrasound** | Swin-Net (Transformer) | BUSI (N=780) | Dice: 0.81 \- 0.89 | Fuzzy Boundaries, Speckle | 10 |
| **Ultrasound** | Multi-Scale Fusion U-Net | BUSIS | Dice: 0.95 | Scale Variation | 11 |
| **DCE-MRI** | nnU-Net / 3D U-Net | Duke/Private (N\>300) | Dice: 0.85 \- 0.93 | 4D Kinetics, Domain Shift | 6 |
| **Mammography** | ARF-Net / U-Net++ | INbreast/CBIS-DDSM | Dice: 0.86 \- 0.92 | Superposition, Tiny Targets | 13 |

## **3\. The Small Dataset Challenge in Medical Image Segmentation**

In the field of medical physics, particularly when investigating novel modalities like Spiral Breast CT or rare pathological subtypes, acquiring massive annotated datasets is often impossible. The "Small Dataset Challenge"—often defined as training with fewer than 50 subjects (N \< 50)—is a pervasive constraint that requires rigorous methodological justification and specific algorithmic strategies.

### **3.1 Justification for Small Sample Sizes (N \< 50\)**

When targeting journals like *Physics in Medicine & Biology*, researchers must explicitly justify the validity of results derived from small cohorts. The review of recent literature reveals three primary justification strategies:

1. **High-Dimensionality and Annotation Effort:** For 3D modalities like SBCT or MRI, a single volume may contain hundreds of slices. Shim et al. (2020) utilized only 58 masses for training but treated the problem as a 2D segmentation task, generating \~7,000 2D slices via augmentation.2 This "slice-based" justification argues that the effective N (number of training examples) is the number of slices, not the number of patients.  
2. **Comparison to Inter-Observer Variability:** A powerful validation strategy for small N is to demonstrate that the DL model's error is within the range of human variability. If a model trained on 40 cases achieves a Dice score of 0.85, and the agreement between two senior radiologists is 0.78, the model is statistically valid for clinical support tasks regardless of the small training set.2  
3. **Prototype/Pilot Status:** Studies utilizing novel hardware, such as the photon-counting breast CT (nu:view), inherently have limited data. In these cases, the papers frame the work as a "feasibility study" or "pilot study," focusing on proof-of-concept rather than large-scale generalization.5

### **3.2 Strategic Solutions to Data Scarcity**

#### **3.2.1 Transfer Learning (TL) and Frozen Encoders**

Transfer learning remains the most effective strategy for small datasets. A critical finding by Raghu et al., cited in recent reviews 16, is that for medical segmentation, the encoder part of the U-Net does not always need to be fully retrained.

* **Frozen Encoder Strategy:** Researchers have shown that initializing a U-Net with weights pretrained on ImageNet (e.g., ResNet50) and *freezing* the encoder (training only the decoder) can achieve comparable accuracy to full fine-tuning on small datasets (N \< 50). This reduces the number of learnable parameters by millions, preventing the massive overfitting that would otherwise occur.16  
* **Cross-Modality Transfer:** Transferring weights from a related medical domain (e.g., Lung CT to Breast CT) is often more effective than transfer from natural images (ImageNet), as the low-level features (edges, textures in Hounsfield units) are more physically consistent.

#### **3.2.2 Few-Shot and Prototypical Learning**

Few-shot learning (FSL) is explicitly designed for N \< 50 scenarios. Prototypical networks learn a metric space where classification is performed by computing distances to prototype representations of each class.

* **Application:** In breast ultrasound, prototype-based networks have been used to segment tumors by learning a "tumor prototype" from a support set of as few as 5 images. The network then segments query images by pixel-wise comparison to this prototype.17 This approach separates the learning of "what a tumor looks like" from the need for thousands of examples.

#### **3.2.3 Generative Data Augmentation (GANs)**

Standard augmentation (rotation, flipping) is insufficient for small datasets because it does not introduce new morphological variations. Generative Adversarial Networks (GANs) have been successfully employed to synthesize realistic lesions.

* **Impact:** In the SBCT study by Shim et al., the addition of GAN-generated synthetic mass images to the training set increased the Dice score by approximately 20% compared to using traditional augmentation alone.2 This provides a compelling argument for the inclusion of synthetic data generation pipelines in medical physics research where patient data is scarce.

## **4\. Small Target and Tiny Lesion Segmentation**

A fundamental geometric challenge in breast cancer imaging is the "Small Target" problem. A 5mm invasive carcinoma in a ![][image2] voxel breast CT volume occupies less than 0.01% of the total volume. Standard segmentation approaches fail in this regime due to extreme class imbalance; a network can achieve \>99.9% accuracy by simply predicting "background" for every voxel.

### **4.1 Failure Modes**

* **Gradient Vanishing:** During backpropagation, the gradient signal from the tiny foreground region is overwhelmed by the massive signal from the background, effectively zeroing out the learning for the lesion class.18  
* **Boundary Ambiguity:** Small targets often suffer from severe partial volume effects (PVE). In SBCT or MRI, a voxel at the edge of a 5mm lesion contains a mixture of tumor and fat signal, leading to intermediate intensity values that confuse standard threshold-based logic.19

### **4.2 Specialized Loss Functions**

To combat the small target problem, the choice of loss function is far more critical than the choice of network architecture.

#### **4.2.1 Focal Loss and Focal Tversky Loss**

Standard Cross-Entropy (CE) loss is ill-suited for class imbalance. **Focal Loss** modifies CE by adding a modulating factor ![][image3] that down-weights "easy" examples (background) and focuses training on "hard" negatives (lesions).

* **Focal Tversky Loss (FTL):** The Tversky index generalizes the Dice coefficient by allowing unequal weighting of False Positives (FP) and False Negatives (FN). For small lesions, missed detections (FN) are far more critical than false positives. FTL allows researchers to penalize FNs more heavily (e.g., setting ![][image4]).  
* **Evidence:** In skin and breast lesion segmentation tasks involving tiny targets, FTL has been shown to improve Dice scores significantly, often raising performance on small lesions from near-zero to acceptable levels (\>0.70).20

#### **4.2.2 Boundary Loss**

For tiny lesions, the surface-to-volume ratio is high. **Boundary Loss** methods approximate the Hausdorff distance and incorporate it into the differentiable loss function. This penalizes the network not just for pixel mismatch (area), but for the distance between the predicted contour and the ground truth.

* **Mechanism:** In breast MRI segmentation, integrating Boundary Loss with Dice Loss (Combined Loss) has proven effective in forcing the network to respect the geometric integrity of small, spiculated tumors, preventing the "blob-like" predictions common with pure Dice loss.22

### **4.3 Architectural Modifications for Small Targets**

* **Adaptive Receptive Fields:** The ARF-Net addressed small targets by dynamically adjusting the receptive field. Small lesions require small kernels to capture local curvature, while large lesions require large kernels for context. Fixed-kernel networks often erode small lesions during pooling operations. ARF-Net's multi-branch approach ensures that features of tiny microcalcifications are preserved alongside larger masses.13  
* **Deep Supervision:** In networks like U-Net++, deep supervision (calculating loss at multiple decoder stages) ensures that the gradient signal for small targets is injected at various depths of the network, preventing it from vanishing before reaching the early layers.14

## **5\. Label Noise and Annotation Uncertainty**

In the domain of Physics in Medicine & Biology, "Ground Truth" is a statistical construct rather than an absolute reality. Pathological confirmation is rarely spatially mapped to the image pixel-by-pixel. Instead, models rely on radiologist annotations, which are subject to significant **inter-observer variability**.

### **5.1 The Magnitude of the Problem**

In breast ultrasound and MRI, the boundaries of lesions are often fuzzy due to infiltration or imaging artifacts. Studies have shown that the variability between two expert radiologists can result in Dice scores of only 0.78-0.85 when comparing their manual segmentations of the same lesion.2 Training a deterministic DL model on such "noisy" labels forces the network to overfit to the biases of a specific annotator rather than learning the underlying biological reality.

### **5.2 Probabilistic Modeling: The Pionono Framework**

To address this, researchers have moved towards **probabilistic segmentation models** that explicitly model the uncertainty distribution.

* **Pionono Model:** Proposed by Schmidt et al., this architecture does not predict a single segmentation mask. Instead, it models the labeling behavior of *each* annotator as a multidimensional probability distribution in a latent space.24  
* **Mechanism:** The network learns a "Gold Distribution" representing the consensus and separate distributions for inter- and intra-observer variability. During inference, the model can generate multiple plausible segmentations for a single image, effectively saying, "This is what Radiologist A would see, and this is what Radiologist B would see."  
* **Clinical Value:** This approach provides a spatial uncertainty map, highlighting regions (usually boundaries) where the model is unsure. For a physicist, this uncertainty map is a critical quality assurance tool, indicating where manual review is necessary.

### **5.3 Soft Labels and Aleatoric Uncertainty**

Another strategy is the use of **soft labels**. Instead of binary masks (0 for background, 1 for tumor), the ground truth is represented as a probability map (e.g., 0.7 for a pixel at a fuzzy boundary).

* **Implementation:** This can be achieved by averaging annotations from multiple experts or by applying label smoothing techniques. Training with soft labels prevents the network from becoming overconfident in ambiguous regions.  
* **Results:** In breast tumor segmentation, soft-label training has been shown to improve the generalization capability of FCNs, making them more robust to the inherent noise in US and MRI data.26 It effectively models the **aleatoric uncertainty**—the uncertainty inherent in the data acquisition physics itself (e.g., PVE in CT voxels).

## **6\. Discussion: Synthesis and Future Directions**

The integration of deep learning into breast imaging has matured from the simple application of off-the-shelf computer vision models to the development of physically-informed, modality-specific architectures.

### **6.1 The Convergence of Physics and AI**

The review highlights a clear trend: the most successful approaches are those that respect the physical characteristics of the modality.

* In **SBCT**, isotropic resolution allows for 2D slice-based approaches that leverage data augmentation to overcome small N, while density (HU) analysis provides a strong feature for discrimination.  
* In **Ultrasound**, the lack of clear boundaries necessitates Transformer-based global context modeling and boundary-aware loss functions.  
* In **MRI**, the kinetic information requires 4D processing or specific handling of temporal channels.

### **6.2 The Roadmap for Small Data**

For researchers in PMB, the "Small Dataset" is not a roadblock but a parameter of the experimental design. The literature confirms that N \< 50 is acceptable *if* accompanied by:

1. Rigorous transfer learning strategies (frozen encoders).  
2. Synthetic augmentation (GANs).  
3. Validation against human inter-observer variability rather than just absolute Dice scores.

### **6.3 Recommendation for Future Research**

Future work must move beyond simple Dice metrics. Papers should report **calibration metrics** (Expected Calibration Error) to quantify how well the model estimates its own uncertainty. Furthermore, **Physics-Guided Loss Functions**—which incorporate constraints such as topology preservation or radiomic feature stability—represent the next frontier. For SBCT specifically, multi-center validation is the critical missing link to prove that these models can generalize across different photon-counting detector technologies.

## **7\. Conclusion**

Deep learning for breast tumor segmentation has achieved expert-level performance across MRI, Ultrasound, and Mammography, and is establishing a strong foothold in the emerging field of Spiral Breast CT. The transition from "black box" CNNs to transparent, uncertainty-aware probabilistic models marks a significant maturation of the field. By leveraging transfer learning to solve data scarcity and advanced loss functions to resolve small targets, medical physicists are now equipped to deploy these tools not just for diagnosis, but for the precise, voxel-level quantification required for the next generation of personalized cancer care.

## **8\. Summary of Key Studies and Metrics**

| Modality | Authors (Year) | Method/Architecture | Dataset Size | Metric (Dice/Conf) | Key Insight/Relevance |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Spiral Breast CT** | Shim et al. (2020) 2 | 2D U-Net | N=93 masses | Conformity: 0.85 | First DL benchmark for SBCT; beat human reader agreement. |
| **Spiral Breast CT** | Shim et al. (2022) 4 | Watershed/Region Growing | N=17 scans | Dice: 0.94 (Skin/Muscle) | Automated tissue segmentation for density quantification. |
| **Spiral Breast CT** | Weber et al. (2024) 5 | ROI Analysis | N=40 patients | AUC: 0.92 (Density) | Established HU density thresholds for lesions vs. dense tissue. |
| **Ultrasound** | Zhu et al. (2024) 10 | Swin-Net (Transformer) | BUSI (N=780) | Dice: 0.818 | Transformers capture global context better than CNNs for fuzzy lesions. |
| **Ultrasound** | Xu et al. (2021) 11 | Multi-Scale Fusion U-Net | BUSIS | Dice: 0.9535 | Multi-scale dilation handles extreme size variation in US lesions. |
| **Mammography** | Xu et al. (2022) 13 | ARF-Net | INbreast/CBIS-DDSM | Dice: 0.86 | Adaptive Receptive Fields solve the "tiny calcification" vs "mass" scale problem. |
| **DCE-MRI** | Zhang et al. (2022) 27 | Mask R-CNN / U-Net | Internal (Large) | Dice: 0.80 \- 0.93 | High contrast allows high performance; 3D context is essential. |
| **Multi-Modality** | Schmidt et al. (2023) 24 | Pionono (Probabilistic) | LIDC / Private | (Probabilistic Metric) | Explicitly models inter-observer variability rather than a single ground truth. |

#### **Works cited**

1. Domain Shift in Breast DCE-MRI Tumor Segmentation: A Balanced LoCoCV Study on the MAMA-MIA Dataset \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC12839833/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12839833/)  
2. Deep learning-based segmentation of breast masses in dedicated breast CT imaging: radiomic feature stability between radiologists and Artificial Intelligence \- PMC \- NIH, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10448305/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10448305/)  
3. J Applied Clin Med Phys \- 2022 \- Shim \- Fully Automated Breast Segmentation On Spiral Breast Computed Tomography Images \- Scribd, accessed February 10, 2026, [https://www.scribd.com/document/810635750/J-Applied-Clin-Med-Phys-2022-Shim-Fully-Automated-Breast-Segmentation-on-Spiral-Breast-Computed-Tomography-Images](https://www.scribd.com/document/810635750/J-Applied-Clin-Med-Phys-2022-Shim-Fully-Automated-Breast-Segmentation-on-Spiral-Breast-Computed-Tomography-Images)  
4. Fully automated breast segmentation on spiral breast computed tomography images \- PMC \- PubMed Central, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9588268/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9588268/)  
5. Potential of non-contrast spiral breast CT to exploit lesion density ..., accessed February 10, 2026, [https://pubmed.ncbi.nlm.nih.gov/39018650/](https://pubmed.ncbi.nlm.nih.gov/39018650/)  
6. Automatic Detection and Segmentation of Breast Cancer on MRI Using Mask R-CNN Trained on Non–Fat-Sat Images and Tested on Fat-Sat Images | Request PDF \- ResearchGate, accessed February 10, 2026, [https://www.researchgate.net/publication/347709756\_Automatic\_Detection\_and\_Segmentation\_of\_Breast\_Cancer\_on\_MRI\_Using\_Mask\_R-CNN\_Trained\_on\_Non-Fat-Sat\_Images\_and\_Tested\_on\_Fat-Sat\_Images](https://www.researchgate.net/publication/347709756_Automatic_Detection_and_Segmentation_of_Breast_Cancer_on_MRI_Using_Mask_R-CNN_Trained_on_Non-Fat-Sat_Images_and_Tested_on_Fat-Sat_Images)  
7. Interactive Machine Learning-Based Multi-Label Segmentation of Solid Tumors and Organs, accessed February 10, 2026, [https://www.mdpi.com/2076-3417/11/16/7488](https://www.mdpi.com/2076-3417/11/16/7488)  
8. UnetTransCNN: integrating transformers with convolutional neural networks for enhanced medical image segmentation \- Frontiers, accessed February 10, 2026, [https://www.frontiersin.org/journals/oncology/articles/10.3389/fonc.2025.1467672/full](https://www.frontiersin.org/journals/oncology/articles/10.3389/fonc.2025.1467672/full)  
9. Unsupervised Learning Techniques for Breast Lesion Segmentation on MRI Images: Are We Ready for Automation? \- MDPI, accessed February 10, 2026, [https://www.mdpi.com/2076-3417/15/5/2401](https://www.mdpi.com/2076-3417/15/5/2401)  
10. Swin-Net: A Swin-Transformer-Based Network Combing with Multi-Scale Features for Segmentation of Breast Tumor Ultrasound Images \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10854866/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10854866/)  
11. Multi-Scale Fusion U-Net for the Segmentation of Breast Lesions ..., accessed February 10, 2026, [https://ieeexplore.ieee.org/document/9558773/](https://ieeexplore.ieee.org/document/9558773/)  
12. D-TransUNet: A Breast Tumor Ultrasound Image Segmentation Model Based on Deep Feature Fusion, accessed February 10, 2026, [https://file.aisacademy.org.cn/journal/article/28/JOAIMS-5-1\_2-1.pdf](https://file.aisacademy.org.cn/journal/article/28/JOAIMS-5-1_2-1.pdf)  
13. ARF-Net: An Adaptive Receptive Field Network for breast mass ..., accessed February 10, 2026, [https://www.researchgate.net/publication/354720774\_ARF-Net\_An\_Adaptive\_Receptive\_Field\_Network\_for\_breast\_mass\_segmentation\_in\_whole\_mammograms\_and\_ultrasound\_images](https://www.researchgate.net/publication/354720774_ARF-Net_An_Adaptive_Receptive_Field_Network_for_breast_mass_segmentation_in_whole_mammograms_and_ultrasound_images)  
14. Enhancing Breast Cancer Segmentation in Mammography with UNet++ \- Deep Learning Approach \- KnE Publishing, accessed February 10, 2026, [https://publish.kne-publishing.com/index.php/fbt/article/download/19818/18516/](https://publish.kne-publishing.com/index.php/fbt/article/download/19818/18516/)  
15. Deep learning applied to breast imaging classification and segmentation with human expert intervention \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9402837/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9402837/)  
16. Transfer Learning in Medical Image Segmentation: New Insights ..., accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8164174/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8164174/)  
17. Attentional adversarial training for few-shot medical image segmentation without annotations | PLOS One \- Research journals, accessed February 10, 2026, [https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0298227](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0298227)  
18. arxiv.org, accessed February 10, 2026, [https://arxiv.org/html/2403.19177v1](https://arxiv.org/html/2403.19177v1)  
19. Deep Learning with Domain Randomization in Image and Feature Spaces for Abdominal Multiorgan Segmentation on CT and MRI Scans | Radiology: Artificial Intelligence \- RSNA Journals, accessed February 10, 2026, [https://pubs.rsna.org/doi/10.1148/ryai.240586](https://pubs.rsna.org/doi/10.1148/ryai.240586)  
20. Attention Res-UNet: Attention Residual UNet With Focal Tversky Loss for Skin Lesion Segmentation \- ResearchGate, accessed February 10, 2026, [https://www.researchgate.net/publication/366775261\_Attention\_Res-UNet\_Attention\_Residual\_UNet\_With\_Focal\_Tversky\_Loss\_for\_Skin\_Lesion\_Segmentation](https://www.researchgate.net/publication/366775261_Attention_Res-UNet_Attention_Residual_UNet_With_Focal_Tversky_Loss_for_Skin_Lesion_Segmentation)  
21. U structured network with three encoding paths for breast tumor ..., accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10703786/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10703786/)  
22. Focal Boundary Dice: Improved Breast Tumor Segmentation from MRI Scan \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10088889/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10088889/)  
23. Skin Lesion Segmentation Using Deep Learning with Auxiliary Task \- MDPI, accessed February 10, 2026, [https://www.mdpi.com/2313-433X/7/4/67](https://www.mdpi.com/2313-433X/7/4/67)  
24. Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation \- decsai, accessed February 10, 2026, [https://ccia.ugr.es/vip/files/conferences/Schmidt\_Probabilistic\_Modeling\_of\_Inter-\_and\_Intra-observer\_Variability\_in\_Medical\_Image\_ICCV\_2023\_paper.pdf](https://ccia.ugr.es/vip/files/conferences/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf)  
25. Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation \- Semantic Scholar API, accessed February 10, 2026, [https://api.semanticscholar.org/arXiv:2307.11397](https://api.semanticscholar.org/arXiv:2307.11397)  
26. A Soft Label Deep Learning to Assist Breast Cancer Target Therapy and Thyroid Cancer Diagnosis \- PMC, accessed February 10, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9657740/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9657740/)  
27. Radiologist-Level Performance by Using Deep Learning for Segmentation of Breast Cancers on MRI Scans | Radiology: Artificial Intelligence \- RSNA Journals, accessed February 10, 2026, [https://pubs.rsna.org/doi/full/10.1148/ryai.200231](https://pubs.rsna.org/doi/full/10.1148/ryai.200231)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACUAAAAXCAYAAACMLIalAAABlElEQVR4Xu2UOy8FQRTHj7fQ0opH4dH6AnS+g0LhA3gkJEKiQKFRoFGISDSiUEn4CApRKCiJCJEgIUiIx3/u2d175uzM3CWSq9hf8sud/c/JzLk7u0uUk1ALb+ETXFFzZeMLtorxanGqfJzC7mhsmtoVcwljcBv2RNddcAuOJhU21fBNh4Jh+Ey84b6ak9TDTx3GzBMvID22KpgzsmtcHMGhaFxFxdq6pIKZhDvEN8TJLFyGm3CGeLEQj+RuqhK+wxaRNRLX+u7sCTzXocE00q/DAL6mBsh9F3V2IcaLlK4vME1/05RhHbapTDZVI8aGQ+JPQ4opuEBcvBH9rlkVNqGmNA3EtZciWyJuZg/eiNxiHB6ozCw0p7KYnzT1QtlrS6KfA0nWpkaI60q9OE4qdAA+yL9xlqZ6KfANyoLZ4M6R+TYu1VQTfFWZfKYyYTaYcGS+jUNNmaN60CH5672Yh7FZXPcRL9IpMkno4Y3/jPZXR2mOTy7Sbk8XMN+Ta+KjMF7Be9gRzQ9SuplY/Xbn5OT8O74Brn5/Dgm4hS0AAAAASUVORK5CYII=>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIYAAAAXCAYAAADOQzd3AAAEd0lEQVR4Xu2ZW8hVRRTHl2UJ+SalD6GQ0VXzilGiYhQUYkSI+CAiJJGSlEYakeJDhkpWJNmFKFELUikUfdDwIcLAF9GHxDRRzO7kpaSim7X+rj3nm/0/M7PnfObBh/nBn3POf61v75l91pnbJ1IoFAqFQqFw6Vio2qS6vfp8q+o91YJWRp2+qj/Z9Jij+lX1r2onxbrFWdXzqsFi7b1Lta+WUWeK2DOI8b5Yf35XLadYt/hKNVXVX3Wdaq6kv4eNqtvYrLhG9blYn46qhtbDBjqKBF/7axnGF1LPCYGHP7t6f6X05PZrZXQH7g+EH4DPYtW5KgZtrodbIHZt9X5k9fmfnnDX4P5AV9cyRPaozlcxyP3YfW5Q/eB93i2Wu9rzLrBMtUa1XrVE7AtN8YvYhZgrVH+phngeqhu5qcq+FOCez4r16TGKhYgVxjOqA2J9cywSy3/Z87qBu+crqjsoxoyReGHA5x+JK6QaKIZ72EwQK4wHJHyDkBfiaTaIQWwk+JuNBmKFsVcs9hr5uX16mA1iOhsJcu7naCoMvtaWypvnm8/J/1MY4B2xocon1JAQE8TmvRA3q75hMwFGrk6IFQbm4g+lPmJgWsztE/52PpsVL6pWsZkg536OVGE8JO0jxidi+Q/6JobcF6rAuur1LT+BSBUGgweL3JMciHCv6gh5t6i+I6+JP1RrVT+rPhBrw/haRp1YYYTA80L+4xyIsF1s+vF5STqfinBPLKo/Ux0W61uMVGGECBb6U6pd5CEJq/oQnRTGb5Kf67hP9WX1HkXxvRfLBW283/t8p1g7BnieD2IYTnNA7mk2G9ghttgFKIpXvVgu/BzRBvYcrjCGcSAApjPkzuBAiGAFVeQWxpNieU2L2RCuOH7kwEWAtqDtIRDDsN8E2vQTm5mgOD5Vvc6BXoLtKto9kQPSUxhNi9Q+YnmPcgAgyGA7FvvycwpjrNi2qbegYxgpjnMgk6vYkHSxw/+ITQJnGQfZ7IB1Ylv+pRzoJZPF2v0G+cAVxggOEMiJri8RPBXwYg+xqTCw58dBkE/uGgOgU25NgSkABzCdMEusfTyvp/oEfyubHk+oPiYvdq0QKApsMwEOD7FO6QR3NuGDwy54oQM3VxijOOCBaf4m7/ONYoeTLTp9iKnCwLRxhk2J5zOjVd+Sh+LgBWmKR8Tudz358GLXQWwbmxWTxE4RmdzR413pKQoHioOfeQq0j3dlKyvfPzdyuMLA8wxxTDWQPCzWcaLaApXjG5PFLoqFX4jUgtIVFCtnWhmuOsFmxTixYTgXbh/md/YcOD1EDKt9BsXFfXFa4eXFeFNsxxdig7RvG2NMk/YRDW04RJ4DR/yIY1Rh8G8K7otTG5hK/ITQ2TmOjzHEY1qAUMFYGWMIAjOl/UZOvOsJgdV6Cn/YawLTGe6LLR1eMbXxWgrnC1hIoh/oz9di6xp/GsRik/vidLeXF6N2YBQAU1QueD64L46z8fp2PXwBLNYRR19cn+D5Pzjuh69CoVAoFAqFQqFQuAz4DyIbX8cdR9k5AAAAAElFTkSuQmCC>

[image3]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEkAAAAYCAYAAAC2odCOAAACSklEQVR4Xu2Yz0sVURTHj5DSDxSDsiJ17d6CClqkYC1UMheRG2shRFGbIFq0aqES6KZFoqC7FoL4D/gHiIguRdpEQkgtchFBuMjzZc68d+frMPe+9+qNA+8DX+be7z137r2HeffdGZEGDf4nA2wUnAds1MpT1Rs2C86oapHNaulSfWPToV31l82CsKEaY1O5LNGaoIvmtamulCIIBJ4mDx2/WlusopI29++qS6o+KbfvlZuT3FL9YZMoepK+qD449V6nDB7Z9WHCdTgU/15U9CQNSvb8T6l22XRB5zNsEnkm6a5qStVsdSx4VdVdigjDN/8lNmJaxd8Z5JUk/KHMqd5JNP5v1XWJEob641KkH8TfZNO4oDrLZswdCVt8Xknat+uMHH/i180LBbFP2DQ+seGCTiEDVZKkFtW1QPEGyry1K/ZNHv9HipcFYqfZNDLvMy6eAKOSJJ1TDQdqyPr4wNgfUzx3Tpuq+06dQSyeyDRus+FyQ8IWzxOqJ0g6xsbhzwXeCtWzQPtLNkM4L/6bgzyTNCnHx15wvGUrx+qJgwi04UxYFeiMfSSLPJMU70dXrd5hdTcZ+OluO/U0apo/Or9i0ziQ6J0Ox3UIZXj1BPObV/20MubBr1Bbkr0f4etGTUl6rfrF5gkBL5xYXCc3EL4E7KhesFkpGARH85PGrPgTAOKYpYRbJuQeXu6pPrOZM8+lvBfiW1dTsjkBfoI4AuDJY9YkWt8/4b1qgs0cwRmqX6J3txFqCwWfQTJP09UwzkbBecZGgwb15whuXY17cIwLTAAAAABJRU5ErkJggg==>

[image4]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAYCAYAAAC4CK7hAAABpElEQVR4Xu2VzSsFURjGX2VBIhuKlI2djT11I9ngT7CwodgoGwt1ZUUsEbY2EisL2+uz5A9QSEpZWQgp+Xxe51x37uPMvTOjLlPzq18dzzNfLzOHSEJCyamGC3CcizixAefsugV+eLrYMAE7KNNBJin795xzIGaQaQ6JZg7+kiVYxaGYQco4dHAEL2ElF6Um+y3UwZRdv3rWQdmG97CBi18wCtdhHxcudsXcXAdSdYjHvCPCsSzmGm1chGAevsMm+/MZvMnVcuJZf9El7t+8DpTmMCRTYq7TS3kx1sS9Y2rWCsvhKnWyx4ElA584jMiwmIcY4MKBvt567AgXYvJNuMOF4ppc0T/rA4cR6RdzH93ii5ER/2fS/BQecqEcc2DRkxY5DMmQmOsMclEAPb7QIM6uG15wCMbE54SApMWc38NFAPR19ru35rccKgfwTfL/V6TEnNDoyYKyAl/EfJBRaZefg9SKedWvPd1Mrs6FV3atzn63wdmCd7Cei4joLpd9HtX7aj7brMaT+e5YYdBdpoLDUqLfRyeHcWSfg7iie3tCQoKbT1WuXEJIc0x+AAAAAElFTkSuQmCC>